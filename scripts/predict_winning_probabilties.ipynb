{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu\\Desktop\\Projets\\Benter\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/Mathieu/Desktop/Projets/Benter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train \n",
    "\n",
    "- predict the best horse in a given race\n",
    "\n",
    "\n",
    "### TODO\n",
    "- try to predict a given distribution according to ranks, instead of the first one\n",
    "- try to predict best among all combinaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from itertools import combinations\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "from scipy.stats import rankdata\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "from utils import import_data\n",
    "from utils import winning_validation\n",
    "from winning_horse_models.sklearn import KNNModel\n",
    "from winning_horse_models.logistic_regression import LogisticRegressionModel\n",
    "from utils import training_procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = \"PMU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequential_sgd_regression = LogisticRegressionModel()\n",
    "#sequential_sgd_regression=training_procedures.train_on_each_horse_with_epochs(source=SOURCE, winning_model=sequential_sgd_regression, n_epochs=10, verbose=True)\n",
    "\n",
    "#sequential_sgd_regression.save_model()\n",
    "\n",
    "sequential_sgd_regression = LogisticRegressionModel.load_model(trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: DtypeWarning: Columns (35,46,47,61,62,63,64,87) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\Mathieu\\Desktop\\Projets\\Benter\\utils\\preprocess.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ) / standard_scaler_parameters[numerical_feature][\"std\"]\n",
      "C:\\Users\\Mathieu\\Desktop\\Projets\\Benter\\utils\\preprocess.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_df[numerical_feature] = features_df[numerical_feature].fillna(0)\n",
      "C:\\Users\\Mathieu\\Desktop\\Projets\\Benter\\utils\\preprocess.py:129: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_df[f\"{ohe_feature}_{value}\"] = features_df[ohe_feature] == value\n",
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\Mathieu\\Desktop\\Projets\\Benter\\utils\\preprocess.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  [\"DEFERRE_ANTERIEURS_POSTERIEURS\", \"DEFERRE_ANTERIEURS\"]\n",
      "C:\\Users\\Mathieu\\Desktop\\Projets\\Benter\\utils\\preprocess.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  [\"DEFERRE_ANTERIEURS_POSTERIEURS\", \"DEFERRE_POSTERIEURS\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For races w/ 2 horses, 1 races in val, top 1 in right order: 0.000% (Random: 0.000%, Odds 100.000%)\n",
      "For races w/ 3 horses, 9 races in val, top 1 in right order: 66.667% (Random: 66.667%, Odds 55.556%)\n",
      "For races w/ 4 horses, 77 races in val, top 1 in right order: 40.260% (Random: 15.584%, Odds 50.649%)\n",
      "For races w/ 5 horses, 354 races in val, top 1 in right order: 35.876% (Random: 16.949%, Odds 44.350%)\n",
      "For races w/ 6 horses, 829 races in val, top 1 in right order: 31.846% (Random: 14.596%, Odds 36.188%)\n",
      "For races w/ 7 horses, 1489 races in val, top 1 in right order: 31.296% (Random: 13.835%, Odds 37.139%)\n",
      "For races w/ 8 horses, 1914 races in val, top 1 in right order: 26.594% (Random: 12.644%, Odds 35.005%)\n",
      "For races w/ 9 horses, 2072 races in val, top 1 in right order: 27.268% (Random: 10.714%, Odds 33.687%)\n",
      "For races w/ 10 horses, 2457 races in val, top 1 in right order: 23.647% (Random: 10.216%, Odds 30.322%)\n",
      "For races w/ 11 horses, 2269 races in val, top 1 in right order: 22.565% (Random: 9.211%, Odds 28.735%)\n",
      "For races w/ 12 horses, 2740 races in val, top 1 in right order: 22.226% (Random: 8.175%, Odds 26.606%)\n",
      "For races w/ 13 horses, 2204 races in val, top 1 in right order: 23.094% (Random: 7.804%, Odds 21.279%)\n",
      "For races w/ 14 horses, 2446 races in val, top 1 in right order: 20.605% (Random: 6.991%, Odds 20.237%)\n",
      "For races w/ 15 horses, 1978 races in val, top 1 in right order: 20.526% (Random: 7.381%, Odds 20.526%)\n",
      "For races w/ 16 horses, 2379 races in val, top 1 in right order: 20.261% (Random: 6.473%, Odds 21.101%)\n",
      "For races w/ 17 horses, 614 races in val, top 1 in right order: 16.450% (Random: 4.235%, Odds 16.124%)\n",
      "For races w/ 18 horses, 757 races in val, top 1 in right order: 17.966% (Random: 5.680%, Odds 21.268%)\n",
      "For races w/ 19 horses, 44 races in val, top 1 in right order: 11.364% (Random: 9.091%, Odds 11.364%)\n",
      "For races w/ 20 horses, 33 races in val, top 1 in right order: 6.061% (Random: 9.091%, Odds 12.121%)\n",
      "For races w/ 21 horses, 5 races in val, top 1 in right order: 0.000% (Random: 60.000%, Odds 40.000%)\n",
      "For races w/ 22 horses, 7 races in val, top 1 in right order: 0.000% (Random: 0.000%, Odds 0.000%)\n",
      "For races w/ 23 horses, 6 races in val, top 1 in right order: 0.000% (Random: 16.667%, Odds 16.667%)\n",
      "For races w/ 24 horses, 6 races in val, top 1 in right order: 16.667% (Random: 0.000%, Odds 16.667%)\n"
     ]
    }
   ],
   "source": [
    "exact_top_1 = winning_validation.compute_validation_error(source=SOURCE, k=1,winning_model=sequential_sgd_regression, validation_method=winning_validation.exact_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_top_5 = winning_validation.compute_validation_error(source=SOURCE, k=5,winning_model=sequential_sgd_regression, validation_method=winning_validation.exact_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_proba_validation.compute_validation_error(source=SOURCE, k=5, winning_model=sequential_sgd_regression,validation_method=winning_proba_validation.same_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_proba_validation.compute_validation_error(source=SOURCE, k=5, winning_model=sequential_sgd_regression,validation_method=winning_proba_validation.precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_validation.compute_predicted_proba_on_actual_races(source=SOURCE, k=5,winning_model=sequential_sgd_regression, same_races_support=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from winning_horse_models.xgboost import XGBoostWinningModel\n",
    "xgboost_winning_model = XGBoostWinningModel.load_model(trainable=False)\n",
    "\n",
    "#xgboost_winning_model, training_history = training_procedures.train_per_horse(source=SOURCE, winning_model=xgboost_winning_model, verbose=True)\n",
    "#xgboost_winning_model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: DtypeWarning: Columns (35,46,47,61,62,63,64,87) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For races w/ 3 horses, 9 races in val, top 1 in right order: 33.333% (Random: 22.222%, Odds 55.556%)\n",
      "For races w/ 4 horses, 77 races in val, top 1 in right order: 31.169% (Random: 35.065%, Odds 50.649%)\n",
      "For races w/ 5 horses, 354 races in val, top 1 in right order: 33.616% (Random: 16.949%, Odds 44.350%)\n",
      "For races w/ 6 horses, 829 races in val, top 1 in right order: 25.935% (Random: 16.888%, Odds 36.188%)\n",
      "For races w/ 7 horses, 1489 races in val, top 1 in right order: 25.789% (Random: 14.909%, Odds 37.139%)\n",
      "For races w/ 8 horses, 1914 races in val, top 1 in right order: 25.914% (Random: 11.755%, Odds 35.005%)\n",
      "For races w/ 9 horses, 2072 races in val, top 1 in right order: 22.153% (Random: 12.403%, Odds 33.687%)\n",
      "For races w/ 10 horses, 2457 races in val, top 1 in right order: 18.519% (Random: 10.623%, Odds 30.322%)\n",
      "For races w/ 11 horses, 2269 races in val, top 1 in right order: 18.378% (Random: 9.079%, Odds 28.735%)\n",
      "For races w/ 12 horses, 2740 races in val, top 1 in right order: 18.321% (Random: 8.102%, Odds 26.606%)\n",
      "For races w/ 13 horses, 2204 races in val, top 1 in right order: 17.604% (Random: 8.167%, Odds 21.279%)\n",
      "For races w/ 14 horses, 2446 races in val, top 1 in right order: 16.680% (Random: 7.236%, Odds 20.237%)\n",
      "For races w/ 15 horses, 1978 races in val, top 1 in right order: 15.925% (Random: 6.623%, Odds 20.526%)\n",
      "For races w/ 16 horses, 2379 races in val, top 1 in right order: 15.216% (Random: 6.515%, Odds 21.101%)\n",
      "For races w/ 17 horses, 614 races in val, top 1 in right order: 13.518% (Random: 6.840%, Odds 16.124%)\n",
      "For races w/ 18 horses, 757 races in val, top 1 in right order: 12.814% (Random: 5.020%, Odds 21.268%)\n",
      "For races w/ 19 horses, 44 races in val, top 1 in right order: 6.818% (Random: 6.818%, Odds 11.364%)\n",
      "For races w/ 20 horses, 33 races in val, top 1 in right order: 9.091% (Random: 0.000%, Odds 12.121%)\n"
     ]
    }
   ],
   "source": [
    "exact_top_1 = winning_validation.compute_validation_error(source=SOURCE, k=1,winning_model=xgboost_winning_model, validation_method=winning_validation.exact_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-5e80926203dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwinning_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_race\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mModelNotCreatedOnceError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_horses_validations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_horses\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"message\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Model was not created\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Projets\\Benter\\winning_horse_models\\xgboost.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_horses_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_horses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_be_fitted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         return model.predict_proba(\n\u001b[0;32m     34\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Projets\\Benter\\winning_horse_models\\xgboost.py\u001b[0m in \u001b[0;36mget_n_horses_model\u001b[1;34m(self, n_horses, should_be_fitted)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_horses_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_horses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshould_be_fitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mcheck_if_xgboost_if_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Projets\\Benter\\winning_horse_models\\xgboost.py\u001b[0m in \u001b[0;36mcheck_if_xgboost_if_fitted\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_if_xgboost_if_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m         \u001b[0mall_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         \u001b[0mall_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mall_features\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "k=1\n",
    "source=\"PMU\"\n",
    "min_horse, max_horse = import_data.get_min_max_horse(source=source)\n",
    "winning_model=xgboost_winning_model\n",
    "from winning_horse_models import AbstractWinningModel, ModelNotCreatedOnceError\n",
    "\n",
    "res={\"n_horses_validations\":{}}\n",
    "for n_horses in range(max(k, min_horse), max_horse + 1):\n",
    "\n",
    "    x_race, rank_race, odds_race = import_data.get_races_per_horse_number(\n",
    "        y_format=\"rank\",\n",
    "        x_format=\"sequential_per_horse\",\n",
    "        n_horses=n_horses,\n",
    "        on_split=\"val\",\n",
    "        source=source,\n",
    "    )\n",
    "    if x_race.size == 0:\n",
    "        res[\"n_horses_validations\"][n_horses] = {\"n_val_races\": 0}\n",
    "        continue\n",
    "    try:\n",
    "        y_hat = winning_model.predict(x=x_race)\n",
    "    except ModelNotCreatedOnceError:\n",
    "        res[\"n_horses_validations\"][n_horses] = {\"message\": \"Model was not created\"}\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3, 49)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_race.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Expecting 2 dimensional numpy.ndarray, got: ', (9, 3, 49))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b48a911cb38e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwinning_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_horses_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_horses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_race\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m    879\u001b[0m         \"\"\"\n\u001b[0;32m    880\u001b[0m         test_dmatrix = DMatrix(data, base_margin=base_margin,\n\u001b[1;32m--> 881\u001b[1;33m                                missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[0;32m    882\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"best_ntree_limit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlazy_isinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'datatable'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Frame'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_dt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[1;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             raise ValueError('Expecting 2 dimensional numpy.ndarray, got: ',\n\u001b[1;32m--> 608\u001b[1;33m                              mat.shape)\n\u001b[0m\u001b[0;32m    609\u001b[0m         \u001b[1;31m# flatten the array by rows and ensure it is float32.  we try to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[1;31m# data copies if possible (reshape returns a view when possible and we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Expecting 2 dimensional numpy.ndarray, got: ', (9, 3, 49))"
     ]
    }
   ],
   "source": [
    "winning_model.get_n_horses_model(n_horses=3).predict(x_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "from constants import SAVED_MODELS_DIR\n",
    "filename = os.listdir(os.path.join(SAVED_MODELS_DIR,cls.__name__))[0]\n",
    "\n",
    "cls = XGBoostWinningModel\n",
    "\n",
    "n_horse_model=XGBClassifier()\n",
    "n_horse_model.load_model(\n",
    "                    fname=os.path.join(SAVED_MODELS_DIR, cls.__name__, filename)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved_models\\\\XGBoostWinningModel\\\\XGBoostWinningModel_10.json'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(SAVED_MODELS_DIR, cls.__name__, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='auto', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_horse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_top_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_proba_validation.compute_validation_error(source=SOURCE, k=5,winning_model=knn_winning_model, validation_method=winning_proba_validation.exact_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_proba_validation.compute_validation_error(source=SOURCE, k=5, winning_model=knn_winning_model,validation_method=winning_proba_validation.same_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_proba_validation.compute_validation_error(source=SOURCE, k=5, winning_model=knn_winning_model,validation_method=winning_proba_validation.precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_proba_validation.compute_predicted_proba_on_actual_races(source=SOURCE, k=5,winning_model=knn_winning_model, same_support=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
