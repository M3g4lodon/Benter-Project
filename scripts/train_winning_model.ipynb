{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mathieu/Prose/Mathieu/Benter-Project\n"
     ]
    }
   ],
   "source": [
    "#%cd C:/Users/Mathieu/Desktop/Projets/Benter\n",
    "%cd /home/mathieu/Prose/Mathieu/Benter-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/.pyenv/versions/3.7.9/envs/benter-project_venv/lib/python3.7/site-packages/tqdm/std.py:699: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from itertools import combinations\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "from scipy.stats import rankdata\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "from utils import import_data\n",
    "from winning_validation import errors\n",
    "from winning_validation import r_squared\n",
    "from winning_horse_models import sklearn\n",
    "from winning_horse_models.logistic_regression import LogisticRegressionModel\n",
    "from winning_horse_models.xgboost import XGBoostWinningModel\n",
    "from winning_horse_models.lgbm import LGBMWinningModel\n",
    "from training_procedures import sequential_training, flattened_training\n",
    "from constants import Sources\n",
    "from utils import preprocess\n",
    "\n",
    "from database.setup import create_sqlalchemy_session\n",
    "from models.race import Race\n",
    "from models.runner import Runner\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = Sources.UNIBET\n",
    "N_FEATURES = preprocess.get_n_preprocessed_feature_columns(source=SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n",
      "No val data for 2\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 1.0270 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 1.0270\n",
      "Training for 2 horses (2 races, val 0 races): loss per horse: 0.513, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 1.3859 - categorical_accuracy: 0.3333 - categorical_crossentropy: 1.3859 - val_loss: 1.1093 - val_categorical_accuracy: 0.2500 - val_categorical_crossentropy: 1.1093\n",
      "Training for 3 horses (27 races, val 4 races): loss per horse: 0.462, val loss per horse: 0.370 Train Accuracy: 33.3%, Val Accuracy: 25.0%\n",
      "\n",
      "11/11 [==============================] - 1s 26ms/step - loss: 1.3204 - categorical_accuracy: 0.3934 - categorical_crossentropy: 1.3204 - val_loss: 1.5097 - val_categorical_accuracy: 0.3111 - val_categorical_crossentropy: 1.5097\n",
      "Training for 4 horses (322 races, val 45 races): loss per horse: 0.329, val loss per horse: 0.377 Train Accuracy: 38.8%, Val Accuracy: 31.1%\n",
      "\n",
      "54/54 [==============================] - 1s 5ms/step - loss: 1.5569 - categorical_accuracy: 0.3296 - categorical_crossentropy: 1.5569 - val_loss: 1.4708 - val_categorical_accuracy: 0.3384 - val_categorical_crossentropy: 1.4708\n",
      "Training for 5 horses (1725 races, val 328 races): loss per horse: 0.307, val loss per horse: 0.294 Train Accuracy: 32.9%, Val Accuracy: 33.8%\n",
      "\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 1.6687 - categorical_accuracy: 0.3117 - categorical_crossentropy: 1.6687 - val_loss: 1.6467 - val_categorical_accuracy: 0.3144 - val_categorical_crossentropy: 1.6467\n",
      "Training for 6 horses (3916 races, val 900 races): loss per horse: 0.275, val loss per horse: 0.274 Train Accuracy: 32.0%, Val Accuracy: 31.4%\n",
      "\n",
      "203/203 [==============================] - 1s 2ms/step - loss: 1.7912 - categorical_accuracy: 0.2920 - categorical_crossentropy: 1.7912 - val_loss: 1.7467 - val_categorical_accuracy: 0.3161 - val_categorical_crossentropy: 1.7467\n",
      "Training for 7 horses (6469 races, val 1642 races): loss per horse: 0.256, val loss per horse: 0.250 Train Accuracy: 29.3%, Val Accuracy: 31.6%\n",
      "\n",
      "292/292 [==============================] - 1s 2ms/step - loss: 1.8899 - categorical_accuracy: 0.2752 - categorical_crossentropy: 1.8899 - val_loss: 1.8620 - val_categorical_accuracy: 0.2931 - val_categorical_crossentropy: 1.8620\n",
      "Training for 8 horses (9336 races, val 2443 races): loss per horse: 0.236, val loss per horse: 0.233 Train Accuracy: 28.2%, Val Accuracy: 29.3%\n",
      "\n",
      "336/336 [==============================] - 1s 1ms/step - loss: 1.9928 - categorical_accuracy: 0.2518 - categorical_crossentropy: 1.9928 - val_loss: 1.9801 - val_categorical_accuracy: 0.2607 - val_categorical_crossentropy: 1.9801\n",
      "Training for 9 horses (10747 races, val 2643 races): loss per horse: 0.221, val loss per horse: 0.220 Train Accuracy: 25.3%, Val Accuracy: 26.1%\n",
      "\n",
      "426/426 [==============================] - 1s 1ms/step - loss: 2.0968 - categorical_accuracy: 0.2376 - categorical_crossentropy: 2.0968 - val_loss: 2.0895 - val_categorical_accuracy: 0.2379 - val_categorical_crossentropy: 2.0895\n",
      "Training for 10 horses (13625 races, val 3182 races): loss per horse: 0.209, val loss per horse: 0.209 Train Accuracy: 24.2%, Val Accuracy: 23.8%\n",
      "\n",
      "403/403 [==============================] - 1s 2ms/step - loss: 2.1587 - categorical_accuracy: 0.2372 - categorical_crossentropy: 2.1587 - val_loss: 2.1707 - val_categorical_accuracy: 0.2311 - val_categorical_crossentropy: 2.1707\n",
      "Training for 11 horses (12874 races, val 2864 races): loss per horse: 0.197, val loss per horse: 0.197 Train Accuracy: 23.2%, Val Accuracy: 23.1%\n",
      "\n",
      "706/706 [==============================] - 1s 1ms/step - loss: 2.2759 - categorical_accuracy: 0.2117 - categorical_crossentropy: 2.2759 - val_loss: 2.2609 - val_categorical_accuracy: 0.2123 - val_categorical_crossentropy: 2.2609\n",
      "Training for 12 horses (22586 races, val 3797 races): loss per horse: 0.189, val loss per horse: 0.188 Train Accuracy: 21.8%, Val Accuracy: 21.2%\n",
      "\n",
      "435/435 [==============================] - 1s 1ms/step - loss: 2.3026 - categorical_accuracy: 0.2202 - categorical_crossentropy: 2.3026 - val_loss: 2.3017 - val_categorical_accuracy: 0.2107 - val_categorical_crossentropy: 2.3017\n",
      "Training for 13 horses (13895 races, val 2729 races): loss per horse: 0.177, val loss per horse: 0.177 Train Accuracy: 21.8%, Val Accuracy: 21.1%\n",
      "\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 2.3817 - categorical_accuracy: 0.2002 - categorical_crossentropy: 2.3817 - val_loss: 2.3535 - val_categorical_accuracy: 0.2154 - val_categorical_crossentropy: 2.3535\n",
      "Training for 14 horses (20846 races, val 3718 races): loss per horse: 0.170, val loss per horse: 0.168 Train Accuracy: 20.4%, Val Accuracy: 21.5%\n",
      "\n",
      "401/401 [==============================] - 1s 1ms/step - loss: 2.4204 - categorical_accuracy: 0.2027 - categorical_crossentropy: 2.4204 - val_loss: 2.4397 - val_categorical_accuracy: 0.2073 - val_categorical_crossentropy: 2.4397\n",
      "Training for 15 horses (12821 races, val 2113 races): loss per horse: 0.162, val loss per horse: 0.163 Train Accuracy: 20.2%, Val Accuracy: 20.7%\n",
      "\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 2.4848 - categorical_accuracy: 0.1955 - categorical_crossentropy: 2.4848 - val_loss: 2.4830 - val_categorical_accuracy: 0.2010 - val_categorical_crossentropy: 2.4830\n",
      "Training for 16 horses (25947 races, val 4586 races): loss per horse: 0.155, val loss per horse: 0.155 Train Accuracy: 19.7%, Val Accuracy: 20.1%\n",
      "\n",
      "128/128 [==============================] - 1s 3ms/step - loss: 2.5744 - categorical_accuracy: 0.1781 - categorical_crossentropy: 2.5744 - val_loss: 2.5468 - val_categorical_accuracy: 0.1933 - val_categorical_crossentropy: 2.5468\n",
      "Training for 17 horses (4075 races, val 652 races): loss per horse: 0.151, val loss per horse: 0.150 Train Accuracy: 17.2%, Val Accuracy: 19.3%\n",
      "\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 2.5646 - categorical_accuracy: 0.1854 - categorical_crossentropy: 2.5646 - val_loss: 2.5569 - val_categorical_accuracy: 0.1729 - val_categorical_crossentropy: 2.5569\n",
      "Training for 18 horses (10272 races, val 1643 races): loss per horse: 0.143, val loss per horse: 0.142 Train Accuracy: 18.1%, Val Accuracy: 17.3%\n",
      "\n",
      "21/21 [==============================] - 1s 13ms/step - loss: 2.7529 - categorical_accuracy: 0.1426 - categorical_crossentropy: 2.7529 - val_loss: 2.6228 - val_categorical_accuracy: 0.3023 - val_categorical_crossentropy: 2.6228\n",
      "Training for 19 horses (657 races, val 43 races): loss per horse: 0.146, val loss per horse: 0.138 Train Accuracy: 14.8%, Val Accuracy: 30.2%\n",
      "\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 2.7884 - categorical_accuracy: 0.1331 - categorical_crossentropy: 2.7884 - val_loss: 2.9630 - val_categorical_accuracy: 0.0659 - val_categorical_crossentropy: 2.9630\n",
      "Training for 20 horses (1989 races, val 91 races): loss per horse: 0.140, val loss per horse: 0.148 Train Accuracy: 12.6%, Val Accuracy: 6.6%\n",
      "\n",
      "2/2 [==============================] - 1s 261ms/step - loss: 2.9011 - categorical_accuracy: 0.2384 - categorical_crossentropy: 2.9011 - val_loss: 3.0967 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.0967\n",
      "Training for 21 horses (43 races, val 3 races): loss per horse: 0.139, val loss per horse: 0.147 Train Accuracy: 23.3%, Val Accuracy: 0.0%\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.9958 - categorical_accuracy: 0.0938 - categorical_crossentropy: 2.9958WARNING:tensorflow:5 out of the last 59 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf00d1c4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 263ms/step - loss: 2.9995 - categorical_accuracy: 0.0919 - categorical_crossentropy: 2.9995 - val_loss: 2.8038 - val_categorical_accuracy: 0.1538 - val_categorical_crossentropy: 2.8038\n",
      "Training for 22 horses (33 races, val 13 races): loss per horse: 0.136, val loss per horse: 0.127 Train Accuracy: 9.1%, Val Accuracy: 15.4%\n",
      "\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8846 - categorical_accuracy: 0.0870 - categorical_crossentropy: 2.8846WARNING:tensorflow:6 out of the last 60 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf380ae680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 2.8846 - categorical_accuracy: 0.0870 - categorical_crossentropy: 2.8846 - val_loss: 3.3991 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3991\n",
      "Training for 23 horses (23 races, val 5 races): loss per horse: 0.125, val loss per horse: 0.148 Train Accuracy: 8.7%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 69 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcef97383b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0459 - categorical_accuracy: 0.1250 - categorical_crossentropy: 3.0459WARNING:tensorflow:7 out of the last 61 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf0acac9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 145ms/step - loss: 3.1373 - categorical_accuracy: 0.0930 - categorical_crossentropy: 3.1373 - val_loss: 3.1601 - val_categorical_accuracy: 0.0769 - val_categorical_crossentropy: 3.1601\n",
      "Training for 24 horses (71 races, val 13 races): loss per horse: 0.132, val loss per horse: 0.132 Train Accuracy: 8.5%, Val Accuracy: 7.7%\n",
      "\n",
      "\n",
      "No val data for 25\n",
      "WARNING:tensorflow:6 out of the last 72 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf1008d680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 3.3339 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3339\n",
      "Training for 25 horses (5 races, val 0 races): loss per horse: 0.133, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "WARNING:tensorflow:7 out of the last 73 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf083c8d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2173 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2173WARNING:tensorflow:8 out of the last 62 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcef8f388c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 3.2173 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2173 - val_loss: 2.9586 - val_categorical_accuracy: 0.1429 - val_categorical_crossentropy: 2.9586\n",
      "Training for 26 horses (6 races, val 7 races): loss per horse: 0.124, val loss per horse: 0.114 Train Accuracy: 0.0%, Val Accuracy: 14.3%\n",
      "\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcef225def0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0902 - categorical_accuracy: 0.5000 - categorical_crossentropy: 3.0902WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcef8055e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 3.0902 - categorical_accuracy: 0.5000 - categorical_crossentropy: 3.0902 - val_loss: 3.8158 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.8158\n",
      "Training for 27 horses (4 races, val 2 races): loss per horse: 0.114, val loss per horse: 0.141 Train Accuracy: 50.0%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcefbf6f680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2881 - categorical_accuracy: 0.0333 - categorical_crossentropy: 3.2881WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcef960ed40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 3.2881 - categorical_accuracy: 0.0333 - categorical_crossentropy: 3.2881 - val_loss: 3.3723 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3723\n",
      "Training for 28 horses (30 races, val 10 races): loss per horse: 0.117, val loss per horse: 0.120 Train Accuracy: 3.3%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcef1a8f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6292 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.6292WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf1303bf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 3.6292 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.6292 - val_loss: 4.3094 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 4.3094\n",
      "Training for 29 horses (7 races, val 1 races): loss per horse: 0.125, val loss per horse: 0.149 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf00d1ccb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3563 - categorical_accuracy: 0.0526 - categorical_crossentropy: 3.3563WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf099d94d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 3.3563 - categorical_accuracy: 0.0526 - categorical_crossentropy: 3.3563 - val_loss: 3.1526 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1526\n",
      "Training for 30 horses (19 races, val 3 races): loss per horse: 0.112, val loss per horse: 0.105 Train Accuracy: 5.3%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf010afd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4119 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4119WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcef25be7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 3.4119 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4119 - val_loss: 3.4960 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.4960\n",
      "Training for 31 horses (3 races, val 2 races): loss per horse: 0.110, val loss per horse: 0.113 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "\n",
      "No val data for 32\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fceb954b560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 3.9737 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9737\n",
      "Training for 32 horses (2 races, val 0 races): loss per horse: 0.124, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf1facecb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4292 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4292WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcefafc5290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 764ms/step - loss: 3.4292 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4292 - val_loss: 3.7218 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.7218\n",
      "Training for 33 horses (5 races, val 4 races): loss per horse: 0.104, val loss per horse: 0.113 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 34\n",
      "WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcee13c93b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7656 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.7656WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf1c4550e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 3.7656 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.7656 - val_loss: 2.6767 - val_categorical_accuracy: 1.0000 - val_categorical_crossentropy: 2.6767\n",
      "Training for 35 horses (1 races, val 1 races): loss per horse: 0.108, val loss per horse: 0.076 Train Accuracy: 0.0%, Val Accuracy: 100.0%\n",
      "\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf021c1b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1992 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.1992WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcee04f3b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 3.1992 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.1992 - val_loss: 3.3014 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3014\n",
      "Training for 36 horses (3 races, val 1 races): loss per horse: 0.089, val loss per horse: 0.092 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 37\n",
      "No training or validation data for 38\n",
      "No training or validation data for 39\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf00ce3440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.9194 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9194WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf08830200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.9194 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9194 - val_loss: 3.0425 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.0425\n",
      "Training for 40 horses (10 races, val 1 races): loss per horse: 0.098, val loss per horse: 0.076 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 41\n",
      "No training or validation data for 42\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcee13c9e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 3.3125 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3125\n",
      "Evaluation only for 43 horses: loss per horse None, val loss per horse: 0.077\n",
      "\n",
      "\n",
      "No val data for 44\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fceb954b830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 4.3259 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 4.3259\n",
      "Training for 44 horses (1 races, val 0 races): loss per horse: 0.098, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "CPU times: user 2h 34min 29s, sys: 2min 35s, total: 2h 37min 5s\n",
      "Wall time: 2h 35min 37s\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "%%time\n",
    "sequential_sgd_regression = LogisticRegressionModel(source=SOURCE, n_features=N_FEATURES)\n",
    "sequential_sgd_regression, training_history =sequential_training.train_on_each_horse_with_epochs(source=SOURCE, winning_model=sequential_sgd_regression, n_epochs=1, verbose=True)\n",
    "\n",
    "sequential_sgd_regression.save_model(prefix=\"48_col_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_sgd_regression = LogisticRegressionModel.load_model(prefix=\"48_col_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 59 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fce348becb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 60 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fce4c3cf320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 61 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf08fcc560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 62 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced11ccdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcefbbb3b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcef25520e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcefbbb3560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcee6568050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcee694f710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf5c1b99e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf5c1c2680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf9c2dca70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf98026950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced11ccf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "(0.2229023589131084, 0.0924753657808301, 0.32284263959390863)\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "exact_top_1 = errors.compute_validation_error(source=SOURCE, k=1,winning_model=sequential_sgd_regression, validation_method=errors.exact_top_k)\n",
    "print(errors.compute_overall_average(exact_top_1))\n",
    "\n",
    "kappa_cohen_1 = errors.compute_validation_error(source=SOURCE, \n",
    "                                                            k=1,\n",
    "                                                            winning_model=sequential_sgd_regression, \n",
    "                                                            validation_method=errors.kappa_cohen_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.14700073613270376, 0.003320176199196662, 0.2571769690533504)\n"
     ]
    }
   ],
   "source": [
    "print(errors.compute_overall_average(kappa_cohen_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing on same races w/ 3 horses with odds 3 races (4 races in total)\n",
      "Mean Predicted probas of actual race result: 48.073% (Random: 19.251%, Odds: 40.856%)\n",
      "\n",
      "Comparing on same races w/ 4 horses with odds 40 races (45 races in total)\n",
      "Mean Predicted probas of actual race result: 29.962% (Random: 21.939%, Odds: 37.649%)\n",
      "\n",
      "Comparing on same races w/ 5 horses with odds 287 races (328 races in total)\n",
      "Mean Predicted probas of actual race result: 27.293% (Random: 19.517%, Odds: 34.718%)\n",
      "\n",
      "Comparing on same races w/ 6 horses with odds 737 races (900 races in total)\n",
      "Mean Predicted probas of actual race result: 21.060% (Random: 16.428%, Odds: 27.936%)\n",
      "\n",
      "Comparing on same races w/ 7 horses with odds 1285 races (1642 races in total)\n",
      "Mean Predicted probas of actual race result: 19.659% (Random: 14.496%, Odds: 26.404%)\n",
      "\n",
      "Comparing on same races w/ 8 horses with odds 1764 races (2443 races in total)\n",
      "Mean Predicted probas of actual race result: 17.482% (Random: 12.687%, Odds: 24.742%)\n",
      "\n",
      "Comparing on same races w/ 9 horses with odds 1850 races (2643 races in total)\n",
      "Mean Predicted probas of actual race result: 15.418% (Random: 11.345%, Odds: 22.285%)\n",
      "\n",
      "Comparing on same races w/ 10 horses with odds 2196 races (3182 races in total)\n",
      "Mean Predicted probas of actual race result: 13.984% (Random: 9.983%, Odds: 20.823%)\n",
      "\n",
      "Comparing on same races w/ 11 horses with odds 1946 races (2864 races in total)\n",
      "Mean Predicted probas of actual race result: 12.970% (Random: 9.042%, Odds: 19.537%)\n",
      "\n",
      "Comparing on same races w/ 12 horses with odds 2581 races (3797 races in total)\n",
      "Mean Predicted probas of actual race result: 11.622% (Random: 8.450%, Odds: 17.866%)\n",
      "\n",
      "Comparing on same races w/ 13 horses with odds 1645 races (2729 races in total)\n",
      "Mean Predicted probas of actual race result: 11.440% (Random: 7.636%, Odds: 17.128%)\n",
      "\n",
      "Comparing on same races w/ 14 horses with odds 2193 races (3718 races in total)\n",
      "Mean Predicted probas of actual race result: 10.871% (Random: 7.045%, Odds: 15.760%)\n",
      "\n",
      "Comparing on same races w/ 15 horses with odds 1132 races (2113 races in total)\n",
      "Mean Predicted probas of actual race result: 9.922% (Random: 6.696%, Odds: 15.303%)\n",
      "\n",
      "Comparing on same races w/ 16 horses with odds 2413 races (4586 races in total)\n",
      "Mean Predicted probas of actual race result: 9.266% (Random: 6.211%, Odds: 14.458%)\n",
      "\n",
      "Comparing on same races w/ 17 horses with odds 286 races (652 races in total)\n",
      "Mean Predicted probas of actual race result: 8.805% (Random: 6.060%, Odds: 13.064%)\n",
      "\n",
      "Comparing on same races w/ 18 horses with odds 698 races (1643 races in total)\n",
      "Mean Predicted probas of actual race result: 8.347% (Random: 5.615%, Odds: 13.413%)\n",
      "\n",
      "Comparing on same races w/ 19 horses with odds 14 races (43 races in total)\n",
      "Mean Predicted probas of actual race result: 7.738% (Random: 5.584%, Odds: 12.937%)\n",
      "\n",
      "Comparing on same races w/ 20 horses with odds 26 races (91 races in total)\n",
      "Mean Predicted probas of actual race result: 5.532% (Random: 5.728%, Odds: 9.525%)\n",
      "\n",
      "Comparing on same races w/ 21 horses with odds 0 races (3 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 22 horses with odds 2 races (13 races in total)\n",
      "Mean Predicted probas of actual race result: 5.892% (Random: 5.431%, Odds: 3.539%)\n",
      "\n",
      "Comparing on same races w/ 23 horses with odds 1 races (5 races in total)\n",
      "Mean Predicted probas of actual race result: 4.322% (Random: 3.565%, Odds: 14.491%)\n",
      "\n",
      "Comparing on same races w/ 24 horses with odds 5 races (13 races in total)\n",
      "Mean Predicted probas of actual race result: 4.442% (Random: 5.514%, Odds: 9.607%)\n",
      "\n",
      "Comparing on same races w/ 26 horses with odds 0 races (7 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/Prose/Mathieu/Benter-Project/winning_validation/r_squared.py:163: RuntimeWarning: Mean of empty slice.\n",
      "  f\"Mean Predicted probas of actual race result: \"\n",
      "/home/mathieu/.pyenv/versions/3.7.9/envs/benter-project_venv/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing on same races w/ 27 horses with odds 0 races (2 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 28 horses with odds 1 races (10 races in total)\n",
      "Mean Predicted probas of actual race result: 3.331% (Random: 5.774%, Odds: 3.105%)\n",
      "\n",
      "Comparing on same races w/ 29 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 30 horses with odds 0 races (3 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 31 horses with odds 1 races (2 races in total)\n",
      "Mean Predicted probas of actual race result: 2.201% (Random: 3.741%, Odds: 2.156%)\n",
      "\n",
      "Comparing on same races w/ 33 horses with odds 0 races (4 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 35 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 36 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 40 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 43 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "On 3 races with 3 horses,R² of winning model: 0.32, R² of odds: 0.16, [R² of random model: -1.16 (should be closed to 0)]\n",
      "On 40 races with 4 horses,R² of winning model: 0.05, R² of odds: 0.17, [R² of random model: -0.26 (should be closed to 0)]\n",
      "On 287 races with 5 horses,R² of winning model: 0.12, R² of odds: 0.25, [R² of random model: -0.20 (should be closed to 0)]\n",
      "On 737 races with 6 horses,R² of winning model: 0.07, R² of odds: 0.16, [R² of random model: -0.16 (should be closed to 0)]\n",
      "On 1285 races with 7 horses,R² of winning model: 0.10, R² of odds: 0.19, [R² of random model: -0.14 (should be closed to 0)]\n",
      "On 1764 races with 8 horses,R² of winning model: 0.10, R² of odds: 0.21, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 1850 races with 9 horses,R² of winning model: 0.09, R² of odds: 0.19, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 2196 races with 10 horses,R² of winning model: 0.08, R² of odds: 0.19, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 1946 races with 11 horses,R² of winning model: 0.09, R² of odds: 0.19, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 2581 races with 12 horses,R² of winning model: 0.08, R² of odds: 0.18, [R² of random model: -0.11 (should be closed to 0)]\n",
      "On 1645 races with 13 horses,R² of winning model: 0.09, R² of odds: 0.18, [R² of random model: -0.12 (should be closed to 0)]\n",
      "On 2193 races with 14 horses,R² of winning model: 0.10, R² of odds: 0.17, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 1132 races with 15 horses,R² of winning model: 0.09, R² of odds: 0.18, [R² of random model: -0.10 (should be closed to 0)]\n",
      "On 2413 races with 16 horses,R² of winning model: 0.09, R² of odds: 0.18, [R² of random model: -0.11 (should be closed to 0)]\n",
      "On 286 races with 17 horses,R² of winning model: 0.09, R² of odds: 0.16, [R² of random model: -0.09 (should be closed to 0)]\n",
      "On 698 races with 18 horses,R² of winning model: 0.09, R² of odds: 0.19, [R² of random model: -0.10 (should be closed to 0)]\n",
      "On 14 races with 19 horses,R² of winning model: 0.07, R² of odds: 0.11, [R² of random model: -0.12 (should be closed to 0)]\n",
      "On 26 races with 20 horses,R² of winning model: -0.02, R² of odds: 0.08, [R² of random model: -0.05 (should be closed to 0)]\n",
      "On 0 races with 21 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 2 races with 22 horses,R² of winning model: 0.06, R² of odds: -0.08, [R² of random model: 0.06 (should be closed to 0)]\n",
      "On 1 races with 23 horses,R² of winning model: -0.00, R² of odds: 0.38, [R² of random model: -0.06 (should be closed to 0)]\n",
      "On 5 races with 24 horses,R² of winning model: -0.04, R² of odds: 0.25, [R² of random model: 0.08 (should be closed to 0)]\n",
      "On 0 races with 26 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 27 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 1 races with 28 horses,R² of winning model: -0.02, R² of odds: -0.04, [R² of random model: 0.14 (should be closed to 0)]\n",
      "On 0 races with 29 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 30 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 1 races with 31 horses,R² of winning model: -0.11, R² of odds: -0.12, [R² of random model: 0.04 (should be closed to 0)]\n",
      "On 0 races with 33 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 35 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 36 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 40 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 43 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "Average Winning Model R²: nan, Average Odds R²: nan (Average Random R²: nan)\n",
      "Combined Winning Model R²: 0.088, Combined Odds R²: 0.185 (Combined Random R²: -0.121) \n",
      "Delta Model vs Odds: -0.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/Prose/Mathieu/Benter-Project/winning_validation/r_squared.py:200: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  -n_races * np.log(n_horses)\n",
      "/home/mathieu/Prose/Mathieu/Benter-Project/winning_validation/r_squared.py:204: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  odds_r_squared = 1 - np.sum(np.log(odds_proba)) / (-n_races * np.log(n_horses))\n",
      "/home/mathieu/Prose/Mathieu/Benter-Project/winning_validation/r_squared.py:208: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  -n_races * np.log(n_horses)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_horses_r_squared': {3: {'model_r_squared': 0.3199518679669403,\n",
       "   'odds_r_squared': 0.16174488735854864,\n",
       "   'random_r_squared': -1.1567870085819605,\n",
       "   'n_races': 3,\n",
       "   'n_rejected_races': 0},\n",
       "  4: {'model_r_squared': 0.04838334496364094,\n",
       "   'odds_r_squared': 0.17443008029053897,\n",
       "   'random_r_squared': -0.2638522211438925,\n",
       "   'n_races': 40,\n",
       "   'n_rejected_races': 0},\n",
       "  5: {'model_r_squared': 0.1188531971478467,\n",
       "   'odds_r_squared': 0.24501564971518353,\n",
       "   'random_r_squared': -0.19893567369267884,\n",
       "   'n_races': 287,\n",
       "   'n_rejected_races': 0},\n",
       "  6: {'model_r_squared': 0.06972517015540647,\n",
       "   'odds_r_squared': 0.1640584706648457,\n",
       "   'random_r_squared': -0.15517132130257028,\n",
       "   'n_races': 737,\n",
       "   'n_rejected_races': 0},\n",
       "  7: {'model_r_squared': 0.09557863728221849,\n",
       "   'odds_r_squared': 0.1870765948715638,\n",
       "   'random_r_squared': -0.13839741292274388,\n",
       "   'n_races': 1285,\n",
       "   'n_rejected_races': 0},\n",
       "  8: {'model_r_squared': 0.0972932252097275,\n",
       "   'odds_r_squared': 0.2072795225420433,\n",
       "   'random_r_squared': -0.13273779087946846,\n",
       "   'n_races': 1764,\n",
       "   'n_rejected_races': 0},\n",
       "  9: {'model_r_squared': 0.0864433285755718,\n",
       "   'odds_r_squared': 0.18956543110915947,\n",
       "   'random_r_squared': -0.12703857708015232,\n",
       "   'n_races': 1850,\n",
       "   'n_rejected_races': 0},\n",
       "  10: {'model_r_squared': 0.08389339161170883,\n",
       "   'odds_r_squared': 0.19096965205005967,\n",
       "   'random_r_squared': -0.12783852545077123,\n",
       "   'n_races': 2196,\n",
       "   'n_rejected_races': 0},\n",
       "  11: {'model_r_squared': 0.08652907123164721,\n",
       "   'odds_r_squared': 0.1896927642180799,\n",
       "   'random_r_squared': -0.12764658592494604,\n",
       "   'n_races': 1946,\n",
       "   'n_rejected_races': 0},\n",
       "  12: {'model_r_squared': 0.07562272609862553,\n",
       "   'odds_r_squared': 0.1833125991975766,\n",
       "   'random_r_squared': -0.10589854352339101,\n",
       "   'n_races': 2581,\n",
       "   'n_rejected_races': 0},\n",
       "  13: {'model_r_squared': 0.09421764638445307,\n",
       "   'odds_r_squared': 0.1841538668018441,\n",
       "   'random_r_squared': -0.1165002294251356,\n",
       "   'n_races': 1645,\n",
       "   'n_rejected_races': 0},\n",
       "  14: {'model_r_squared': 0.1013048663887961,\n",
       "   'odds_r_squared': 0.1737785016245904,\n",
       "   'random_r_squared': -0.1300366266980204,\n",
       "   'n_races': 2193,\n",
       "   'n_rejected_races': 0},\n",
       "  15: {'model_r_squared': 0.08794084613360531,\n",
       "   'odds_r_squared': 0.17677641403009992,\n",
       "   'random_r_squared': -0.10486404109202874,\n",
       "   'n_races': 1132,\n",
       "   'n_rejected_races': 0},\n",
       "  16: {'model_r_squared': 0.08642595755954796,\n",
       "   'odds_r_squared': 0.17542939588385553,\n",
       "   'random_r_squared': -0.10507382516597152,\n",
       "   'n_races': 2413,\n",
       "   'n_rejected_races': 0},\n",
       "  17: {'model_r_squared': 0.0881898980146163,\n",
       "   'odds_r_squared': 0.16135182313906538,\n",
       "   'random_r_squared': -0.0943542132137809,\n",
       "   'n_races': 286,\n",
       "   'n_rejected_races': 0},\n",
       "  18: {'model_r_squared': 0.08917721668313106,\n",
       "   'odds_r_squared': 0.19420519647851187,\n",
       "   'random_r_squared': -0.10483472458192211,\n",
       "   'n_races': 698,\n",
       "   'n_rejected_races': 0},\n",
       "  19: {'model_r_squared': 0.06564496197384262,\n",
       "   'odds_r_squared': 0.11230459802929926,\n",
       "   'random_r_squared': -0.11826500737581225,\n",
       "   'n_races': 14,\n",
       "   'n_rejected_races': 0},\n",
       "  20: {'model_r_squared': -0.01960444531975991,\n",
       "   'odds_r_squared': 0.08270865809153527,\n",
       "   'random_r_squared': -0.05308841779760454,\n",
       "   'n_races': 26,\n",
       "   'n_rejected_races': 0},\n",
       "  21: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  22: {'model_r_squared': 0.058854412729545835,\n",
       "   'odds_r_squared': -0.08146388191884335,\n",
       "   'random_r_squared': 0.0558460086150101,\n",
       "   'n_races': 2,\n",
       "   'n_rejected_races': 0},\n",
       "  23: {'model_r_squared': -0.0019239876900396524,\n",
       "   'odds_r_squared': 0.38395360522813304,\n",
       "   'random_r_squared': -0.06330193028890996,\n",
       "   'n_races': 1,\n",
       "   'n_rejected_races': 0},\n",
       "  24: {'model_r_squared': -0.037658442445366314,\n",
       "   'odds_r_squared': 0.25132385608732,\n",
       "   'random_r_squared': 0.07791873016621809,\n",
       "   'n_races': 5,\n",
       "   'n_rejected_races': 0},\n",
       "  26: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  27: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  28: {'model_r_squared': -0.020926061362296133,\n",
       "   'odds_r_squared': -0.042018247996860714,\n",
       "   'random_r_squared': 0.1441852152110834,\n",
       "   'n_races': 1,\n",
       "   'n_rejected_races': 0},\n",
       "  29: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  30: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  31: {'model_r_squared': -0.1113634384247415,\n",
       "   'odds_r_squared': -0.11735959147483821,\n",
       "   'random_r_squared': 0.043136282751492505,\n",
       "   'n_races': 1,\n",
       "   'n_rejected_races': 0},\n",
       "  33: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  35: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  36: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  40: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  43: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0}},\n",
       " 'average_model_r_squared': nan,\n",
       " 'average_odds_r_squared': nan,\n",
       " 'average_random_r_squared': nan,\n",
       " 'combined_model_r_squared': 0.08820863408293433,\n",
       " 'combined_odds_r_squared': 0.18451068776442836,\n",
       " 'combined_random_r_squared': -0.12068816769876145,\n",
       " 'delta_model_odds': -0.09630205368149403}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared.compute_mcfadden_r_squared(source=SOURCE,winning_model=sequential_sgd_regression, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n",
      "No val data for 2\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf98039200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.2207 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 1.2207\n",
      "Training for 2 horses (2 races, val 0 races): loss per horse: 0.610, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fce4cbbf3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3419 - categorical_accuracy: 0.2593 - categorical_crossentropy: 1.3419WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf8812b050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 1.3419 - categorical_accuracy: 0.2593 - categorical_crossentropy: 1.3419 - val_loss: 0.9882 - val_categorical_accuracy: 0.5000 - val_categorical_crossentropy: 0.9882\n",
      "Training for 3 horses (27 races, val 4 races): loss per horse: 0.447, val loss per horse: 0.329 Train Accuracy: 25.9%, Val Accuracy: 50.0%\n",
      "\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf98039320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " 1/11 [=>............................] - ETA: 2s - loss: 1.3936 - categorical_accuracy: 0.2188 - categorical_crossentropy: 1.3936WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf5c62f8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.3230 - categorical_accuracy: 0.3744 - categorical_crossentropy: 1.3230 - val_loss: 1.5115 - val_categorical_accuracy: 0.3333 - val_categorical_crossentropy: 1.5115\n",
      "Training for 4 horses (322 races, val 45 races): loss per horse: 0.331, val loss per horse: 0.378 Train Accuracy: 40.1%, Val Accuracy: 33.3%\n",
      "\n",
      " 1/54 [..............................] - ETA: 15s - loss: 1.4100 - categorical_accuracy: 0.4375 - categorical_crossentropy: 1.4100WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcee694f4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "54/54 [==============================] - 1s 4ms/step - loss: 1.5122 - categorical_accuracy: 0.3528 - categorical_crossentropy: 1.5122 - val_loss: 1.4674 - val_categorical_accuracy: 0.3445 - val_categorical_crossentropy: 1.4674\n",
      "Training for 5 horses (1725 races, val 328 races): loss per horse: 0.300, val loss per horse: 0.293 Train Accuracy: 35.0%, Val Accuracy: 34.5%\n",
      "\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 1.6318 - categorical_accuracy: 0.3266 - categorical_crossentropy: 1.6318 - val_loss: 1.6419 - val_categorical_accuracy: 0.3200 - val_categorical_crossentropy: 1.6419\n",
      "Training for 6 horses (3916 races, val 900 races): loss per horse: 0.272, val loss per horse: 0.274 Train Accuracy: 33.0%, Val Accuracy: 32.0%\n",
      "\n",
      "203/203 [==============================] - 1s 2ms/step - loss: 1.7911 - categorical_accuracy: 0.2938 - categorical_crossentropy: 1.7911 - val_loss: 1.7455 - val_categorical_accuracy: 0.3124 - val_categorical_crossentropy: 1.7455\n",
      "Training for 7 horses (6469 races, val 1642 races): loss per horse: 0.255, val loss per horse: 0.249 Train Accuracy: 29.6%, Val Accuracy: 31.2%\n",
      "\n",
      "292/292 [==============================] - 1s 1ms/step - loss: 1.8949 - categorical_accuracy: 0.2791 - categorical_crossentropy: 1.8949 - val_loss: 1.8645 - val_categorical_accuracy: 0.2849 - val_categorical_crossentropy: 1.8645\n",
      "Training for 8 horses (9336 races, val 2443 races): loss per horse: 0.236, val loss per horse: 0.233 Train Accuracy: 28.0%, Val Accuracy: 28.5%\n",
      "\n",
      "336/336 [==============================] - 1s 1ms/step - loss: 1.9932 - categorical_accuracy: 0.2528 - categorical_crossentropy: 1.9932 - val_loss: 1.9832 - val_categorical_accuracy: 0.2614 - val_categorical_crossentropy: 1.9832\n",
      "Training for 9 horses (10747 races, val 2643 races): loss per horse: 0.222, val loss per horse: 0.220 Train Accuracy: 25.4%, Val Accuracy: 26.1%\n",
      "\n",
      "426/426 [==============================] - 1s 1ms/step - loss: 2.0974 - categorical_accuracy: 0.2411 - categorical_crossentropy: 2.0974 - val_loss: 2.0926 - val_categorical_accuracy: 0.2376 - val_categorical_crossentropy: 2.0926\n",
      "Training for 10 horses (13625 races, val 3182 races): loss per horse: 0.209, val loss per horse: 0.209 Train Accuracy: 23.8%, Val Accuracy: 23.8%\n",
      "\n",
      "403/403 [==============================] - 1s 1ms/step - loss: 2.1688 - categorical_accuracy: 0.2300 - categorical_crossentropy: 2.1688 - val_loss: 2.1712 - val_categorical_accuracy: 0.2252 - val_categorical_crossentropy: 2.1712\n",
      "Training for 11 horses (12874 races, val 2864 races): loss per horse: 0.197, val loss per horse: 0.197 Train Accuracy: 23.1%, Val Accuracy: 22.5%\n",
      "\n",
      "706/706 [==============================] - 1s 1ms/step - loss: 2.2740 - categorical_accuracy: 0.2125 - categorical_crossentropy: 2.2740 - val_loss: 2.2631 - val_categorical_accuracy: 0.2099 - val_categorical_crossentropy: 2.2631\n",
      "Training for 12 horses (22586 races, val 3797 races): loss per horse: 0.189, val loss per horse: 0.189 Train Accuracy: 21.7%, Val Accuracy: 21.0%\n",
      "\n",
      "435/435 [==============================] - 1s 1ms/step - loss: 2.3124 - categorical_accuracy: 0.2162 - categorical_crossentropy: 2.3124 - val_loss: 2.3009 - val_categorical_accuracy: 0.2118 - val_categorical_crossentropy: 2.3009\n",
      "Training for 13 horses (13895 races, val 2729 races): loss per horse: 0.177, val loss per horse: 0.177 Train Accuracy: 21.8%, Val Accuracy: 21.2%\n",
      "\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 2.3870 - categorical_accuracy: 0.2023 - categorical_crossentropy: 2.3870 - val_loss: 2.3466 - val_categorical_accuracy: 0.2227 - val_categorical_crossentropy: 2.3466\n",
      "Training for 14 horses (20846 races, val 3718 races): loss per horse: 0.170, val loss per horse: 0.168 Train Accuracy: 20.3%, Val Accuracy: 22.3%\n",
      "\n",
      "401/401 [==============================] - 1s 1ms/step - loss: 2.4179 - categorical_accuracy: 0.2054 - categorical_crossentropy: 2.4179 - val_loss: 2.4397 - val_categorical_accuracy: 0.2044 - val_categorical_crossentropy: 2.4397\n",
      "Training for 15 horses (12821 races, val 2113 races): loss per horse: 0.162, val loss per horse: 0.163 Train Accuracy: 20.1%, Val Accuracy: 20.4%\n",
      "\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 2.4871 - categorical_accuracy: 0.1973 - categorical_crossentropy: 2.4871 - val_loss: 2.4862 - val_categorical_accuracy: 0.1980 - val_categorical_crossentropy: 2.4862\n",
      "Training for 16 horses (25947 races, val 4586 races): loss per horse: 0.155, val loss per horse: 0.155 Train Accuracy: 19.6%, Val Accuracy: 19.8%\n",
      "\n",
      "128/128 [==============================] - 1s 3ms/step - loss: 2.5609 - categorical_accuracy: 0.1729 - categorical_crossentropy: 2.5609 - val_loss: 2.5468 - val_categorical_accuracy: 0.1933 - val_categorical_crossentropy: 2.5468\n",
      "Training for 17 horses (4075 races, val 652 races): loss per horse: 0.151, val loss per horse: 0.150 Train Accuracy: 17.2%, Val Accuracy: 19.3%\n",
      "\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 2.5606 - categorical_accuracy: 0.1860 - categorical_crossentropy: 2.5606 - val_loss: 2.5578 - val_categorical_accuracy: 0.1759 - val_categorical_crossentropy: 2.5578\n",
      "Training for 18 horses (10272 races, val 1643 races): loss per horse: 0.143, val loss per horse: 0.142 Train Accuracy: 18.0%, Val Accuracy: 17.6%\n",
      "\n",
      "21/21 [==============================] - 1s 13ms/step - loss: 2.7703 - categorical_accuracy: 0.1482 - categorical_crossentropy: 2.7703 - val_loss: 2.6352 - val_categorical_accuracy: 0.3023 - val_categorical_crossentropy: 2.6352\n",
      "Training for 19 horses (657 races, val 43 races): loss per horse: 0.146, val loss per horse: 0.139 Train Accuracy: 15.4%, Val Accuracy: 30.2%\n",
      "\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 2.8046 - categorical_accuracy: 0.1373 - categorical_crossentropy: 2.8046 - val_loss: 2.9689 - val_categorical_accuracy: 0.0659 - val_categorical_crossentropy: 2.9689\n",
      "Training for 20 horses (1989 races, val 91 races): loss per horse: 0.140, val loss per horse: 0.148 Train Accuracy: 12.7%, Val Accuracy: 6.6%\n",
      "\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 2.9321 - categorical_accuracy: 0.2020 - categorical_crossentropy: 2.9321 - val_loss: 3.1200 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1200\n",
      "Training for 21 horses (43 races, val 3 races): loss per horse: 0.139, val loss per horse: 0.149 Train Accuracy: 20.9%, Val Accuracy: 0.0%\n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.9885 - categorical_accuracy: 0.0938 - categorical_crossentropy: 2.9885WARNING:tensorflow:5 out of the last 59 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcef9550c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 257ms/step - loss: 2.9922 - categorical_accuracy: 0.0919 - categorical_crossentropy: 2.9922 - val_loss: 2.8133 - val_categorical_accuracy: 0.1538 - val_categorical_crossentropy: 2.8133\n",
      "Training for 22 horses (33 races, val 13 races): loss per horse: 0.136, val loss per horse: 0.128 Train Accuracy: 9.1%, Val Accuracy: 15.4%\n",
      "\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.9042 - categorical_accuracy: 0.0870 - categorical_crossentropy: 2.9042WARNING:tensorflow:6 out of the last 60 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf383bf4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 2.9042 - categorical_accuracy: 0.0870 - categorical_crossentropy: 2.9042 - val_loss: 3.3813 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3813\n",
      "Training for 23 horses (23 races, val 5 races): loss per horse: 0.126, val loss per horse: 0.147 Train Accuracy: 8.7%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 69 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcef3123cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2403 - categorical_accuracy: 0.0312 - categorical_crossentropy: 3.2403WARNING:tensorflow:7 out of the last 61 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf1fd04b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 129ms/step - loss: 3.1857 - categorical_accuracy: 0.0735 - categorical_crossentropy: 3.1857 - val_loss: 3.1700 - val_categorical_accuracy: 0.0769 - val_categorical_crossentropy: 3.1700\n",
      "Training for 24 horses (71 races, val 13 races): loss per horse: 0.132, val loss per horse: 0.132 Train Accuracy: 8.5%, Val Accuracy: 7.7%\n",
      "\n",
      "\n",
      "No val data for 25\n",
      "WARNING:tensorflow:6 out of the last 72 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf133748c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 3.3711 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3711\n",
      "Training for 25 horses (5 races, val 0 races): loss per horse: 0.135, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "WARNING:tensorflow:7 out of the last 73 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcee72d2b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2433 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2433WARNING:tensorflow:8 out of the last 62 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcef81d9cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 3.2433 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2433 - val_loss: 2.9795 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 2.9795\n",
      "Training for 26 horses (6 races, val 7 races): loss per horse: 0.125, val loss per horse: 0.115 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcee177b680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0796 - categorical_accuracy: 0.5000 - categorical_crossentropy: 3.0796WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf1e0f8050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 3.0796 - categorical_accuracy: 0.5000 - categorical_crossentropy: 3.0796 - val_loss: 3.8328 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.8328\n",
      "Training for 27 horses (4 races, val 2 races): loss per horse: 0.114, val loss per horse: 0.142 Train Accuracy: 50.0%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7fce3537e710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2928 - categorical_accuracy: 0.0333 - categorical_crossentropy: 3.2928WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf1e3c2d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 3.2928 - categorical_accuracy: 0.0333 - categorical_crossentropy: 3.2928 - val_loss: 3.3828 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3828\n",
      "Training for 28 horses (30 races, val 10 races): loss per horse: 0.118, val loss per horse: 0.121 Train Accuracy: 3.3%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcefbc434d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6203 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.6203WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf39b80320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 3.6203 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.6203 - val_loss: 4.2911 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 4.2911\n",
      "Training for 29 horses (7 races, val 1 races): loss per horse: 0.125, val loss per horse: 0.148 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf1cc3c830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.3502 - categorical_accuracy: 0.0526 - categorical_crossentropy: 3.3502WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcefbd1bf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 3.3502 - categorical_accuracy: 0.0526 - categorical_crossentropy: 3.3502 - val_loss: 3.1744 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1744\n",
      "Training for 30 horses (19 races, val 3 races): loss per horse: 0.112, val loss per horse: 0.106 Train Accuracy: 5.3%, Val Accuracy: 0.0%\n",
      "\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf0bccbb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4431 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4431WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcee0349710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 761ms/step - loss: 3.4431 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4431 - val_loss: 3.4981 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.4981\n",
      "Training for 31 horses (3 races, val 2 races): loss per horse: 0.111, val loss per horse: 0.113 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "\n",
      "No val data for 32\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced8e7dd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 4.0067 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 4.0067\n",
      "Training for 32 horses (2 races, val 0 races): loss per horse: 0.125, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf0affea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4076 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4076WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf5c3ce320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 760ms/step - loss: 3.4076 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4076 - val_loss: 3.7203 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.7203\n",
      "Training for 33 horses (5 races, val 4 races): loss per horse: 0.103, val loss per horse: 0.113 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 34\n",
      "WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf00c50e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7216 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.7216WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf1e8f0d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 3.7216 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.7216 - val_loss: 2.6369 - val_categorical_accuracy: 1.0000 - val_categorical_crossentropy: 2.6369\n",
      "Training for 35 horses (1 races, val 1 races): loss per horse: 0.106, val loss per horse: 0.075 Train Accuracy: 0.0%, Val Accuracy: 100.0%\n",
      "\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf08aa1e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2187 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2187WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf00b645f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 3.2187 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2187 - val_loss: 3.3095 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3095\n",
      "Training for 36 horses (3 races, val 1 races): loss per horse: 0.089, val loss per horse: 0.092 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 37\n",
      "No training or validation data for 38\n",
      "No training or validation data for 39\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf09f6fc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.9101 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9101WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf1f1f17a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 3.9101 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9101 - val_loss: 3.0418 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.0418\n",
      "Training for 40 horses (10 races, val 1 races): loss per horse: 0.098, val loss per horse: 0.076 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 41\n",
      "No training or validation data for 42\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fcf3939fc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 3.3003 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3003\n",
      "Evaluation only for 43 horses: loss per horse None, val loss per horse: 0.077\n",
      "\n",
      "\n",
      "No val data for 44\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcf1edbb9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 4.3579 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 4.3579\n",
      "Training for 44 horses (1 races, val 0 races): loss per horse: 0.099, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Epoch 1\n",
      "\n",
      "No val data for 2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4943 - categorical_accuracy: 1.0000 - categorical_crossentropy: 0.4943\n",
      "Training for 2 horses (2 races, val 0 races): loss per horse: 0.247, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.0128 - categorical_accuracy: 0.5926 - categorical_crossentropy: 1.0128 - val_loss: 1.0166 - val_categorical_accuracy: 0.2500 - val_categorical_crossentropy: 1.0166\n",
      "Training for 3 horses (27 races, val 4 races): loss per horse: 0.338, val loss per horse: 0.339 Train Accuracy: 59.3%, Val Accuracy: 25.0%\n",
      "\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.2078 - categorical_accuracy: 0.4720 - categorical_crossentropy: 1.2078 - val_loss: 1.3461 - val_categorical_accuracy: 0.3556 - val_categorical_crossentropy: 1.3461\n",
      "Training for 4 horses (322 races, val 45 races): loss per horse: 0.302, val loss per horse: 0.337 Train Accuracy: 47.2%, Val Accuracy: 35.6%\n",
      "\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4441 - categorical_accuracy: 0.3745 - categorical_crossentropy: 1.4441 - val_loss: 1.4286 - val_categorical_accuracy: 0.3963 - val_categorical_crossentropy: 1.4286\n",
      "Training for 5 horses (1725 races, val 328 races): loss per horse: 0.289, val loss per horse: 0.286 Train Accuracy: 37.4%, Val Accuracy: 39.6%\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.6085 - categorical_accuracy: 0.3368 - categorical_crossentropy: 1.6085 - val_loss: 1.6406 - val_categorical_accuracy: 0.3189 - val_categorical_crossentropy: 1.6406\n",
      "Training for 6 horses (3916 races, val 900 races): loss per horse: 0.268, val loss per horse: 0.273 Train Accuracy: 33.7%, Val Accuracy: 31.9%\n",
      "\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.7656 - categorical_accuracy: 0.3025 - categorical_crossentropy: 1.7656 - val_loss: 1.7414 - val_categorical_accuracy: 0.3240 - val_categorical_crossentropy: 1.7414\n",
      "Training for 7 horses (6469 races, val 1642 races): loss per horse: 0.252, val loss per horse: 0.249 Train Accuracy: 30.3%, Val Accuracy: 32.4%\n",
      "\n",
      "292/292 [==============================] - 0s 1ms/step - loss: 1.8735 - categorical_accuracy: 0.2813 - categorical_crossentropy: 1.8735 - val_loss: 1.8604 - val_categorical_accuracy: 0.2841 - val_categorical_crossentropy: 1.8604\n",
      "Training for 8 horses (9336 races, val 2443 races): loss per horse: 0.234, val loss per horse: 0.233 Train Accuracy: 28.1%, Val Accuracy: 28.4%\n",
      "\n",
      "336/336 [==============================] - 0s 1ms/step - loss: 1.9833 - categorical_accuracy: 0.2542 - categorical_crossentropy: 1.9833 - val_loss: 1.9769 - val_categorical_accuracy: 0.2671 - val_categorical_crossentropy: 1.9769\n",
      "Training for 9 horses (10747 races, val 2643 races): loss per horse: 0.220, val loss per horse: 0.220 Train Accuracy: 25.4%, Val Accuracy: 26.7%\n",
      "\n",
      "426/426 [==============================] - 0s 1ms/step - loss: 2.0842 - categorical_accuracy: 0.2417 - categorical_crossentropy: 2.0842 - val_loss: 2.0869 - val_categorical_accuracy: 0.2370 - val_categorical_crossentropy: 2.0869\n",
      "Training for 10 horses (13625 races, val 3182 races): loss per horse: 0.208, val loss per horse: 0.209 Train Accuracy: 24.2%, Val Accuracy: 23.7%\n",
      "\n",
      "403/403 [==============================] - 0s 1ms/step - loss: 2.1575 - categorical_accuracy: 0.2344 - categorical_crossentropy: 2.1575 - val_loss: 2.1660 - val_categorical_accuracy: 0.2263 - val_categorical_crossentropy: 2.1660\n",
      "Training for 11 horses (12874 races, val 2864 races): loss per horse: 0.196, val loss per horse: 0.197 Train Accuracy: 23.4%, Val Accuracy: 22.6%\n",
      "\n",
      "706/706 [==============================] - 1s 919us/step - loss: 2.2532 - categorical_accuracy: 0.2204 - categorical_crossentropy: 2.2532 - val_loss: 2.2533 - val_categorical_accuracy: 0.2175 - val_categorical_crossentropy: 2.2533\n",
      "Training for 12 horses (22586 races, val 3797 races): loss per horse: 0.188, val loss per horse: 0.188 Train Accuracy: 22.0%, Val Accuracy: 21.8%\n",
      "\n",
      "435/435 [==============================] - 0s 1ms/step - loss: 2.2983 - categorical_accuracy: 0.2191 - categorical_crossentropy: 2.2983 - val_loss: 2.2922 - val_categorical_accuracy: 0.2169 - val_categorical_crossentropy: 2.2922\n",
      "Training for 13 horses (13895 races, val 2729 races): loss per horse: 0.177, val loss per horse: 0.176 Train Accuracy: 21.9%, Val Accuracy: 21.7%\n",
      "\n",
      "652/652 [==============================] - 1s 964us/step - loss: 2.3743 - categorical_accuracy: 0.2050 - categorical_crossentropy: 2.3743 - val_loss: 2.3485 - val_categorical_accuracy: 0.2189 - val_categorical_crossentropy: 2.3485\n",
      "Training for 14 horses (20846 races, val 3718 races): loss per horse: 0.170, val loss per horse: 0.168 Train Accuracy: 20.5%, Val Accuracy: 21.9%\n",
      "\n",
      "401/401 [==============================] - 0s 1ms/step - loss: 2.4209 - categorical_accuracy: 0.2051 - categorical_crossentropy: 2.4209 - val_loss: 2.4370 - val_categorical_accuracy: 0.2063 - val_categorical_crossentropy: 2.4370\n",
      "Training for 15 horses (12821 races, val 2113 races): loss per horse: 0.161, val loss per horse: 0.162 Train Accuracy: 20.5%, Val Accuracy: 20.6%\n",
      "\n",
      "811/811 [==============================] - 1s 998us/step - loss: 2.4838 - categorical_accuracy: 0.1971 - categorical_crossentropy: 2.4838 - val_loss: 2.4839 - val_categorical_accuracy: 0.1991 - val_categorical_crossentropy: 2.4839\n",
      "Training for 16 horses (25947 races, val 4586 races): loss per horse: 0.155, val loss per horse: 0.155 Train Accuracy: 19.7%, Val Accuracy: 19.9%\n",
      "\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 2.5654 - categorical_accuracy: 0.1698 - categorical_crossentropy: 2.5654 - val_loss: 2.5421 - val_categorical_accuracy: 0.1948 - val_categorical_crossentropy: 2.5421\n",
      "Training for 17 horses (4075 races, val 652 races): loss per horse: 0.151, val loss per horse: 0.150 Train Accuracy: 17.0%, Val Accuracy: 19.5%\n",
      "\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 2.5737 - categorical_accuracy: 0.1823 - categorical_crossentropy: 2.5737 - val_loss: 2.5586 - val_categorical_accuracy: 0.1735 - val_categorical_crossentropy: 2.5586\n",
      "Training for 18 horses (10272 races, val 1643 races): loss per horse: 0.143, val loss per horse: 0.142 Train Accuracy: 18.2%, Val Accuracy: 17.3%\n",
      "\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.7702 - categorical_accuracy: 0.1492 - categorical_crossentropy: 2.7702 - val_loss: 2.6289 - val_categorical_accuracy: 0.2791 - val_categorical_crossentropy: 2.6289\n",
      "Training for 19 horses (657 races, val 43 races): loss per horse: 0.146, val loss per horse: 0.138 Train Accuracy: 14.9%, Val Accuracy: 27.9%\n",
      "\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.8006 - categorical_accuracy: 0.1272 - categorical_crossentropy: 2.8006 - val_loss: 2.9641 - val_categorical_accuracy: 0.0879 - val_categorical_crossentropy: 2.9641\n",
      "Training for 20 horses (1989 races, val 91 races): loss per horse: 0.140, val loss per horse: 0.148 Train Accuracy: 12.7%, Val Accuracy: 8.8%\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 2.9121 - categorical_accuracy: 0.2326 - categorical_crossentropy: 2.9121 - val_loss: 3.1372 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1372\n",
      "Training for 21 horses (43 races, val 3 races): loss per horse: 0.139, val loss per horse: 0.149 Train Accuracy: 23.3%, Val Accuracy: 0.0%\n",
      "\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 2.9856 - categorical_accuracy: 0.0909 - categorical_crossentropy: 2.9856 - val_loss: 2.8260 - val_categorical_accuracy: 0.0769 - val_categorical_crossentropy: 2.8260\n",
      "Training for 22 horses (33 races, val 13 races): loss per horse: 0.136, val loss per horse: 0.128 Train Accuracy: 9.1%, Val Accuracy: 7.7%\n",
      "\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 2.8802 - categorical_accuracy: 0.0435 - categorical_crossentropy: 2.8802 - val_loss: 3.3900 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3900\n",
      "Training for 23 horses (23 races, val 5 races): loss per horse: 0.125, val loss per horse: 0.147 Train Accuracy: 4.3%, Val Accuracy: 0.0%\n",
      "\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.1860 - categorical_accuracy: 0.0704 - categorical_crossentropy: 3.1860 - val_loss: 3.1593 - val_categorical_accuracy: 0.0769 - val_categorical_crossentropy: 3.1593\n",
      "Training for 24 horses (71 races, val 13 races): loss per horse: 0.133, val loss per horse: 0.132 Train Accuracy: 7.0%, Val Accuracy: 7.7%\n",
      "\n",
      "\n",
      "No val data for 25\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3666 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3666\n",
      "Training for 25 horses (5 races, val 0 races): loss per horse: 0.135, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.2368 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2368 - val_loss: 2.9666 - val_categorical_accuracy: 0.1429 - val_categorical_crossentropy: 2.9666\n",
      "Training for 26 horses (6 races, val 7 races): loss per horse: 0.124, val loss per horse: 0.114 Train Accuracy: 0.0%, Val Accuracy: 14.3%\n",
      "\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.0707 - categorical_accuracy: 0.5000 - categorical_crossentropy: 3.0707 - val_loss: 3.7885 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.7885\n",
      "Training for 27 horses (4 races, val 2 races): loss per horse: 0.114, val loss per horse: 0.140 Train Accuracy: 50.0%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 3.2801 - categorical_accuracy: 0.0333 - categorical_crossentropy: 3.2801 - val_loss: 3.3840 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3840\n",
      "Training for 28 horses (30 races, val 10 races): loss per horse: 0.117, val loss per horse: 0.121 Train Accuracy: 3.3%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 3.6350 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.6350 - val_loss: 4.3381 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 4.3381\n",
      "Training for 29 horses (7 races, val 1 races): loss per horse: 0.125, val loss per horse: 0.150 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.3646 - categorical_accuracy: 0.0526 - categorical_crossentropy: 3.3646 - val_loss: 3.1672 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1672\n",
      "Training for 30 horses (19 races, val 3 races): loss per horse: 0.112, val loss per horse: 0.106 Train Accuracy: 5.3%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.3964 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3964 - val_loss: 3.5304 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.5304\n",
      "Training for 31 horses (3 races, val 2 races): loss per horse: 0.110, val loss per horse: 0.114 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "\n",
      "No val data for 32\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0041 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 4.0041\n",
      "Training for 32 horses (2 races, val 0 races): loss per horse: 0.125, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 3.4114 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4114 - val_loss: 3.7816 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.7816\n",
      "Training for 33 horses (5 races, val 4 races): loss per horse: 0.103, val loss per horse: 0.115 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 34\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.7274 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.7274 - val_loss: 2.5767 - val_categorical_accuracy: 1.0000 - val_categorical_crossentropy: 2.5767\n",
      "Training for 35 horses (1 races, val 1 races): loss per horse: 0.106, val loss per horse: 0.074 Train Accuracy: 0.0%, Val Accuracy: 100.0%\n",
      "\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 3.1888 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.1888 - val_loss: 3.3031 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3031\n",
      "Training for 36 horses (3 races, val 1 races): loss per horse: 0.089, val loss per horse: 0.092 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 37\n",
      "No training or validation data for 38\n",
      "No training or validation data for 39\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.9303 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9303 - val_loss: 3.0237 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.0237\n",
      "Training for 40 horses (10 races, val 1 races): loss per horse: 0.098, val loss per horse: 0.076 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 41\n",
      "No training or validation data for 42\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2836 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2836\n",
      "Evaluation only for 43 horses: loss per horse None, val loss per horse: 0.076\n",
      "\n",
      "\n",
      "No val data for 44\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3383 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 4.3383\n",
      "Training for 44 horses (1 races, val 0 races): loss per horse: 0.099, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "No val data for 2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5101 - categorical_accuracy: 1.0000 - categorical_crossentropy: 0.5101\n",
      "Training for 2 horses (2 races, val 0 races): loss per horse: 0.255, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.0237 - categorical_accuracy: 0.5556 - categorical_crossentropy: 1.0237 - val_loss: 1.0003 - val_categorical_accuracy: 0.2500 - val_categorical_crossentropy: 1.0003\n",
      "Training for 3 horses (27 races, val 4 races): loss per horse: 0.341, val loss per horse: 0.333 Train Accuracy: 55.6%, Val Accuracy: 25.0%\n",
      "\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2035 - categorical_accuracy: 0.4627 - categorical_crossentropy: 1.2035 - val_loss: 1.3488 - val_categorical_accuracy: 0.3556 - val_categorical_crossentropy: 1.3488\n",
      "Training for 4 horses (322 races, val 45 races): loss per horse: 0.301, val loss per horse: 0.337 Train Accuracy: 46.3%, Val Accuracy: 35.6%\n",
      "\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4414 - categorical_accuracy: 0.3762 - categorical_crossentropy: 1.4414 - val_loss: 1.4290 - val_categorical_accuracy: 0.3963 - val_categorical_crossentropy: 1.4290\n",
      "Training for 5 horses (1725 races, val 328 races): loss per horse: 0.288, val loss per horse: 0.286 Train Accuracy: 37.6%, Val Accuracy: 39.6%\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.6066 - categorical_accuracy: 0.3350 - categorical_crossentropy: 1.6066 - val_loss: 1.6396 - val_categorical_accuracy: 0.3144 - val_categorical_crossentropy: 1.6396\n",
      "Training for 6 horses (3916 races, val 900 races): loss per horse: 0.268, val loss per horse: 0.273 Train Accuracy: 33.5%, Val Accuracy: 31.4%\n",
      "\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.7628 - categorical_accuracy: 0.3011 - categorical_crossentropy: 1.7628 - val_loss: 1.7412 - val_categorical_accuracy: 0.3240 - val_categorical_crossentropy: 1.7412\n",
      "Training for 7 horses (6469 races, val 1642 races): loss per horse: 0.252, val loss per horse: 0.249 Train Accuracy: 30.1%, Val Accuracy: 32.4%\n",
      "\n",
      "292/292 [==============================] - 0s 1ms/step - loss: 1.8709 - categorical_accuracy: 0.2816 - categorical_crossentropy: 1.8709 - val_loss: 1.8586 - val_categorical_accuracy: 0.2882 - val_categorical_crossentropy: 1.8586\n",
      "Training for 8 horses (9336 races, val 2443 races): loss per horse: 0.234, val loss per horse: 0.232 Train Accuracy: 28.2%, Val Accuracy: 28.8%\n",
      "\n",
      "336/336 [==============================] - 0s 1ms/step - loss: 1.9813 - categorical_accuracy: 0.2564 - categorical_crossentropy: 1.9813 - val_loss: 1.9782 - val_categorical_accuracy: 0.2641 - val_categorical_crossentropy: 1.9782\n",
      "Training for 9 horses (10747 races, val 2643 races): loss per horse: 0.220, val loss per horse: 0.220 Train Accuracy: 25.6%, Val Accuracy: 26.4%\n",
      "\n",
      "426/426 [==============================] - 0s 1ms/step - loss: 2.0822 - categorical_accuracy: 0.2407 - categorical_crossentropy: 2.0822 - val_loss: 2.0842 - val_categorical_accuracy: 0.2382 - val_categorical_crossentropy: 2.0842\n",
      "Training for 10 horses (13625 races, val 3182 races): loss per horse: 0.208, val loss per horse: 0.208 Train Accuracy: 24.1%, Val Accuracy: 23.8%\n",
      "\n",
      "403/403 [==============================] - 0s 1ms/step - loss: 2.1560 - categorical_accuracy: 0.2357 - categorical_crossentropy: 2.1560 - val_loss: 2.1616 - val_categorical_accuracy: 0.2270 - val_categorical_crossentropy: 2.1616\n",
      "Training for 11 horses (12874 races, val 2864 races): loss per horse: 0.196, val loss per horse: 0.197 Train Accuracy: 23.6%, Val Accuracy: 22.7%\n",
      "\n",
      "706/706 [==============================] - 1s 937us/step - loss: 2.2524 - categorical_accuracy: 0.2195 - categorical_crossentropy: 2.2524 - val_loss: 2.2536 - val_categorical_accuracy: 0.2149 - val_categorical_crossentropy: 2.2536\n",
      "Training for 12 horses (22586 races, val 3797 races): loss per horse: 0.188, val loss per horse: 0.188 Train Accuracy: 22.0%, Val Accuracy: 21.5%\n",
      "\n",
      "435/435 [==============================] - 0s 1ms/step - loss: 2.2967 - categorical_accuracy: 0.2209 - categorical_crossentropy: 2.2967 - val_loss: 2.2925 - val_categorical_accuracy: 0.2199 - val_categorical_crossentropy: 2.2925\n",
      "Training for 13 horses (13895 races, val 2729 races): loss per horse: 0.177, val loss per horse: 0.176 Train Accuracy: 22.1%, Val Accuracy: 22.0%\n",
      "\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 2.3728 - categorical_accuracy: 0.2050 - categorical_crossentropy: 2.3728 - val_loss: 2.3429 - val_categorical_accuracy: 0.2224 - val_categorical_crossentropy: 2.3429\n",
      "Training for 14 horses (20846 races, val 3718 races): loss per horse: 0.169, val loss per horse: 0.167 Train Accuracy: 20.5%, Val Accuracy: 22.2%\n",
      "\n",
      "401/401 [==============================] - 1s 1ms/step - loss: 2.4195 - categorical_accuracy: 0.2047 - categorical_crossentropy: 2.4195 - val_loss: 2.4361 - val_categorical_accuracy: 0.2073 - val_categorical_crossentropy: 2.4361\n",
      "Training for 15 horses (12821 races, val 2113 races): loss per horse: 0.161, val loss per horse: 0.162 Train Accuracy: 20.5%, Val Accuracy: 20.7%\n",
      "\n",
      "811/811 [==============================] - 1s 966us/step - loss: 2.4822 - categorical_accuracy: 0.1976 - categorical_crossentropy: 2.4822 - val_loss: 2.4817 - val_categorical_accuracy: 0.1978 - val_categorical_crossentropy: 2.4817\n",
      "Training for 16 horses (25947 races, val 4586 races): loss per horse: 0.155, val loss per horse: 0.155 Train Accuracy: 19.8%, Val Accuracy: 19.8%\n",
      "\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 2.5647 - categorical_accuracy: 0.1688 - categorical_crossentropy: 2.5647 - val_loss: 2.5405 - val_categorical_accuracy: 0.1948 - val_categorical_crossentropy: 2.5405\n",
      "Training for 17 horses (4075 races, val 652 races): loss per horse: 0.151, val loss per horse: 0.149 Train Accuracy: 16.9%, Val Accuracy: 19.5%\n",
      "\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 2.5729 - categorical_accuracy: 0.1835 - categorical_crossentropy: 2.5729 - val_loss: 2.5552 - val_categorical_accuracy: 0.1722 - val_categorical_crossentropy: 2.5552\n",
      "Training for 18 horses (10272 races, val 1643 races): loss per horse: 0.143, val loss per horse: 0.142 Train Accuracy: 18.4%, Val Accuracy: 17.2%\n",
      "\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.7700 - categorical_accuracy: 0.1492 - categorical_crossentropy: 2.7700 - val_loss: 2.6154 - val_categorical_accuracy: 0.3256 - val_categorical_crossentropy: 2.6154\n",
      "Training for 19 horses (657 races, val 43 races): loss per horse: 0.146, val loss per horse: 0.138 Train Accuracy: 14.9%, Val Accuracy: 32.6%\n",
      "\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.8005 - categorical_accuracy: 0.1287 - categorical_crossentropy: 2.8005 - val_loss: 2.9616 - val_categorical_accuracy: 0.0659 - val_categorical_crossentropy: 2.9616\n",
      "Training for 20 horses (1989 races, val 91 races): loss per horse: 0.140, val loss per horse: 0.148 Train Accuracy: 12.9%, Val Accuracy: 6.6%\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 2.9024 - categorical_accuracy: 0.2093 - categorical_crossentropy: 2.9024 - val_loss: 3.1508 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1508\n",
      "Training for 21 horses (43 races, val 3 races): loss per horse: 0.138, val loss per horse: 0.150 Train Accuracy: 20.9%, Val Accuracy: 0.0%\n",
      "\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 2.9878 - categorical_accuracy: 0.1212 - categorical_crossentropy: 2.9878 - val_loss: 2.8303 - val_categorical_accuracy: 0.0769 - val_categorical_crossentropy: 2.8303\n",
      "Training for 22 horses (33 races, val 13 races): loss per horse: 0.136, val loss per horse: 0.129 Train Accuracy: 12.1%, Val Accuracy: 7.7%\n",
      "\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.8729 - categorical_accuracy: 0.0435 - categorical_crossentropy: 2.8729 - val_loss: 3.3986 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3986\n",
      "Training for 23 horses (23 races, val 5 races): loss per horse: 0.125, val loss per horse: 0.148 Train Accuracy: 4.3%, Val Accuracy: 0.0%\n",
      "\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.1945 - categorical_accuracy: 0.0704 - categorical_crossentropy: 3.1945 - val_loss: 3.1573 - val_categorical_accuracy: 0.0769 - val_categorical_crossentropy: 3.1573\n",
      "Training for 24 horses (71 races, val 13 races): loss per horse: 0.133, val loss per horse: 0.132 Train Accuracy: 7.0%, Val Accuracy: 7.7%\n",
      "\n",
      "\n",
      "No val data for 25\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3787 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3787\n",
      "Training for 25 horses (5 races, val 0 races): loss per horse: 0.135, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.2380 - categorical_accuracy: 0.1667 - categorical_crossentropy: 3.2380 - val_loss: 2.9504 - val_categorical_accuracy: 0.1429 - val_categorical_crossentropy: 2.9504\n",
      "Training for 26 horses (6 races, val 7 races): loss per horse: 0.125, val loss per horse: 0.113 Train Accuracy: 16.7%, Val Accuracy: 14.3%\n",
      "\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 3.0486 - categorical_accuracy: 0.5000 - categorical_crossentropy: 3.0486 - val_loss: 3.7206 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.7206\n",
      "Training for 27 horses (4 races, val 2 races): loss per horse: 0.113, val loss per horse: 0.138 Train Accuracy: 50.0%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 3.2624 - categorical_accuracy: 0.0667 - categorical_crossentropy: 3.2624 - val_loss: 3.3873 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3873\n",
      "Training for 28 horses (30 races, val 10 races): loss per horse: 0.117, val loss per horse: 0.121 Train Accuracy: 6.7%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.6469 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.6469 - val_loss: 4.3132 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 4.3132\n",
      "Training for 29 horses (7 races, val 1 races): loss per horse: 0.126, val loss per horse: 0.149 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 3.3688 - categorical_accuracy: 0.0526 - categorical_crossentropy: 3.3688 - val_loss: 3.1653 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1653\n",
      "Training for 30 horses (19 races, val 3 races): loss per horse: 0.112, val loss per horse: 0.106 Train Accuracy: 5.3%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.3942 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3942 - val_loss: 3.5385 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.5385\n",
      "Training for 31 horses (3 races, val 2 races): loss per horse: 0.109, val loss per horse: 0.114 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "\n",
      "No val data for 32\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9657 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9657\n",
      "Training for 32 horses (2 races, val 0 races): loss per horse: 0.124, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.4181 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4181 - val_loss: 3.7907 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.7907\n",
      "Training for 33 horses (5 races, val 4 races): loss per horse: 0.104, val loss per horse: 0.115 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 34\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.7450 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.7450 - val_loss: 2.5659 - val_categorical_accuracy: 1.0000 - val_categorical_crossentropy: 2.5659\n",
      "Training for 35 horses (1 races, val 1 races): loss per horse: 0.107, val loss per horse: 0.073 Train Accuracy: 0.0%, Val Accuracy: 100.0%\n",
      "\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.2080 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2080 - val_loss: 3.3042 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3042\n",
      "Training for 36 horses (3 races, val 1 races): loss per horse: 0.089, val loss per horse: 0.092 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 37\n",
      "No training or validation data for 38\n",
      "No training or validation data for 39\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.9202 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9202 - val_loss: 3.0374 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.0374\n",
      "Training for 40 horses (10 races, val 1 races): loss per horse: 0.098, val loss per horse: 0.076 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 41\n",
      "No training or validation data for 42\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.2771 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2771\n",
      "Evaluation only for 43 horses: loss per horse None, val loss per horse: 0.076\n",
      "\n",
      "\n",
      "No val data for 44\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3046 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 4.3046\n",
      "Training for 44 horses (1 races, val 0 races): loss per horse: 0.098, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Epoch 3\n",
      "\n",
      "No val data for 2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5214 - categorical_accuracy: 1.0000 - categorical_crossentropy: 0.5214\n",
      "Training for 2 horses (2 races, val 0 races): loss per horse: 0.261, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.0193 - categorical_accuracy: 0.5926 - categorical_crossentropy: 1.0193 - val_loss: 0.9899 - val_categorical_accuracy: 0.2500 - val_categorical_crossentropy: 0.9899\n",
      "Training for 3 horses (27 races, val 4 races): loss per horse: 0.340, val loss per horse: 0.330 Train Accuracy: 59.3%, Val Accuracy: 25.0%\n",
      "\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.2013 - categorical_accuracy: 0.4689 - categorical_crossentropy: 1.2013 - val_loss: 1.3553 - val_categorical_accuracy: 0.3556 - val_categorical_crossentropy: 1.3553\n",
      "Training for 4 horses (322 races, val 45 races): loss per horse: 0.300, val loss per horse: 0.339 Train Accuracy: 46.9%, Val Accuracy: 35.6%\n",
      "\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4406 - categorical_accuracy: 0.3809 - categorical_crossentropy: 1.4406 - val_loss: 1.4308 - val_categorical_accuracy: 0.3902 - val_categorical_crossentropy: 1.4308\n",
      "Training for 5 horses (1725 races, val 328 races): loss per horse: 0.288, val loss per horse: 0.286 Train Accuracy: 38.1%, Val Accuracy: 39.0%\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.6064 - categorical_accuracy: 0.3353 - categorical_crossentropy: 1.6064 - val_loss: 1.6397 - val_categorical_accuracy: 0.3122 - val_categorical_crossentropy: 1.6397\n",
      "Training for 6 horses (3916 races, val 900 races): loss per horse: 0.268, val loss per horse: 0.273 Train Accuracy: 33.5%, Val Accuracy: 31.2%\n",
      "\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.7618 - categorical_accuracy: 0.3022 - categorical_crossentropy: 1.7618 - val_loss: 1.7387 - val_categorical_accuracy: 0.3216 - val_categorical_crossentropy: 1.7387\n",
      "Training for 7 horses (6469 races, val 1642 races): loss per horse: 0.252, val loss per horse: 0.248 Train Accuracy: 30.2%, Val Accuracy: 32.2%\n",
      "\n",
      "292/292 [==============================] - 0s 1ms/step - loss: 1.8695 - categorical_accuracy: 0.2842 - categorical_crossentropy: 1.8695 - val_loss: 1.8587 - val_categorical_accuracy: 0.2841 - val_categorical_crossentropy: 1.8587\n",
      "Training for 8 horses (9336 races, val 2443 races): loss per horse: 0.234, val loss per horse: 0.232 Train Accuracy: 28.4%, Val Accuracy: 28.4%\n",
      "\n",
      "336/336 [==============================] - 0s 1ms/step - loss: 1.9800 - categorical_accuracy: 0.2576 - categorical_crossentropy: 1.9800 - val_loss: 1.9727 - val_categorical_accuracy: 0.2686 - val_categorical_crossentropy: 1.9727\n",
      "Training for 9 horses (10747 races, val 2643 races): loss per horse: 0.220, val loss per horse: 0.219 Train Accuracy: 25.8%, Val Accuracy: 26.9%\n",
      "\n",
      "426/426 [==============================] - 0s 1ms/step - loss: 2.0810 - categorical_accuracy: 0.2410 - categorical_crossentropy: 2.0810 - val_loss: 2.0855 - val_categorical_accuracy: 0.2395 - val_categorical_crossentropy: 2.0855\n",
      "Training for 10 horses (13625 races, val 3182 races): loss per horse: 0.208, val loss per horse: 0.209 Train Accuracy: 24.1%, Val Accuracy: 23.9%\n",
      "\n",
      "403/403 [==============================] - 0s 1ms/step - loss: 2.1551 - categorical_accuracy: 0.2369 - categorical_crossentropy: 2.1551 - val_loss: 2.1647 - val_categorical_accuracy: 0.2238 - val_categorical_crossentropy: 2.1647\n",
      "Training for 11 horses (12874 races, val 2864 races): loss per horse: 0.196, val loss per horse: 0.197 Train Accuracy: 23.7%, Val Accuracy: 22.4%\n",
      "\n",
      "706/706 [==============================] - 1s 940us/step - loss: 2.2519 - categorical_accuracy: 0.2215 - categorical_crossentropy: 2.2519 - val_loss: 2.2530 - val_categorical_accuracy: 0.2170 - val_categorical_crossentropy: 2.2530\n",
      "Training for 12 horses (22586 races, val 3797 races): loss per horse: 0.188, val loss per horse: 0.188 Train Accuracy: 22.2%, Val Accuracy: 21.7%\n",
      "\n",
      "435/435 [==============================] - 0s 1ms/step - loss: 2.2962 - categorical_accuracy: 0.2227 - categorical_crossentropy: 2.2962 - val_loss: 2.2921 - val_categorical_accuracy: 0.2177 - val_categorical_crossentropy: 2.2921\n",
      "Training for 13 horses (13895 races, val 2729 races): loss per horse: 0.177, val loss per horse: 0.176 Train Accuracy: 22.3%, Val Accuracy: 21.8%\n",
      "\n",
      "652/652 [==============================] - 1s 992us/step - loss: 2.3722 - categorical_accuracy: 0.2054 - categorical_crossentropy: 2.3722 - val_loss: 2.3424 - val_categorical_accuracy: 0.2211 - val_categorical_crossentropy: 2.3424\n",
      "Training for 14 horses (20846 races, val 3718 races): loss per horse: 0.169, val loss per horse: 0.167 Train Accuracy: 20.5%, Val Accuracy: 22.1%\n",
      "\n",
      "401/401 [==============================] - 0s 1ms/step - loss: 2.4189 - categorical_accuracy: 0.2057 - categorical_crossentropy: 2.4189 - val_loss: 2.4338 - val_categorical_accuracy: 0.2040 - val_categorical_crossentropy: 2.4338\n",
      "Training for 15 horses (12821 races, val 2113 races): loss per horse: 0.161, val loss per horse: 0.162 Train Accuracy: 20.6%, Val Accuracy: 20.4%\n",
      "\n",
      "811/811 [==============================] - 1s 978us/step - loss: 2.4818 - categorical_accuracy: 0.1982 - categorical_crossentropy: 2.4818 - val_loss: 2.4815 - val_categorical_accuracy: 0.1991 - val_categorical_crossentropy: 2.4815\n",
      "Training for 16 horses (25947 races, val 4586 races): loss per horse: 0.155, val loss per horse: 0.155 Train Accuracy: 19.8%, Val Accuracy: 19.9%\n",
      "\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 2.5641 - categorical_accuracy: 0.1686 - categorical_crossentropy: 2.5641 - val_loss: 2.5391 - val_categorical_accuracy: 0.1994 - val_categorical_crossentropy: 2.5391\n",
      "Training for 17 horses (4075 races, val 652 races): loss per horse: 0.151, val loss per horse: 0.149 Train Accuracy: 16.9%, Val Accuracy: 19.9%\n",
      "\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 2.5724 - categorical_accuracy: 0.1830 - categorical_crossentropy: 2.5724 - val_loss: 2.5546 - val_categorical_accuracy: 0.1729 - val_categorical_crossentropy: 2.5546\n",
      "Training for 18 horses (10272 races, val 1643 races): loss per horse: 0.143, val loss per horse: 0.142 Train Accuracy: 18.3%, Val Accuracy: 17.3%\n",
      "\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.7684 - categorical_accuracy: 0.1522 - categorical_crossentropy: 2.7684 - val_loss: 2.6152 - val_categorical_accuracy: 0.3256 - val_categorical_crossentropy: 2.6152\n",
      "Training for 19 horses (657 races, val 43 races): loss per horse: 0.146, val loss per horse: 0.138 Train Accuracy: 15.2%, Val Accuracy: 32.6%\n",
      "\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.7989 - categorical_accuracy: 0.1307 - categorical_crossentropy: 2.7989 - val_loss: 2.9606 - val_categorical_accuracy: 0.0879 - val_categorical_crossentropy: 2.9606\n",
      "Training for 20 horses (1989 races, val 91 races): loss per horse: 0.140, val loss per horse: 0.148 Train Accuracy: 13.1%, Val Accuracy: 8.8%\n",
      "\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 2.8931 - categorical_accuracy: 0.2093 - categorical_crossentropy: 2.8931 - val_loss: 3.1553 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1553\n",
      "Training for 21 horses (43 races, val 3 races): loss per horse: 0.138, val loss per horse: 0.150 Train Accuracy: 20.9%, Val Accuracy: 0.0%\n",
      "\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 2.9773 - categorical_accuracy: 0.1212 - categorical_crossentropy: 2.9773 - val_loss: 2.8172 - val_categorical_accuracy: 0.1538 - val_categorical_crossentropy: 2.8172\n",
      "Training for 22 horses (33 races, val 13 races): loss per horse: 0.135, val loss per horse: 0.128 Train Accuracy: 12.1%, Val Accuracy: 15.4%\n",
      "\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 2.8566 - categorical_accuracy: 0.1304 - categorical_crossentropy: 2.8566 - val_loss: 3.4239 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.4239\n",
      "Training for 23 horses (23 races, val 5 races): loss per horse: 0.124, val loss per horse: 0.149 Train Accuracy: 13.0%, Val Accuracy: 0.0%\n",
      "\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.1895 - categorical_accuracy: 0.0704 - categorical_crossentropy: 3.1895 - val_loss: 3.1429 - val_categorical_accuracy: 0.0769 - val_categorical_crossentropy: 3.1429\n",
      "Training for 24 horses (71 races, val 13 races): loss per horse: 0.133, val loss per horse: 0.131 Train Accuracy: 7.0%, Val Accuracy: 7.7%\n",
      "\n",
      "\n",
      "No val data for 25\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3626 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3626\n",
      "Training for 25 horses (5 races, val 0 races): loss per horse: 0.135, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.2217 - categorical_accuracy: 0.1667 - categorical_crossentropy: 3.2217 - val_loss: 2.9346 - val_categorical_accuracy: 0.1429 - val_categorical_crossentropy: 2.9346\n",
      "Training for 26 horses (6 races, val 7 races): loss per horse: 0.124, val loss per horse: 0.113 Train Accuracy: 16.7%, Val Accuracy: 14.3%\n",
      "\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.0436 - categorical_accuracy: 0.5000 - categorical_crossentropy: 3.0436 - val_loss: 3.6744 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.6744\n",
      "Training for 27 horses (4 races, val 2 races): loss per horse: 0.113, val loss per horse: 0.136 Train Accuracy: 50.0%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.2442 - categorical_accuracy: 0.0667 - categorical_crossentropy: 3.2442 - val_loss: 3.3778 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3778\n",
      "Training for 28 horses (30 races, val 10 races): loss per horse: 0.116, val loss per horse: 0.121 Train Accuracy: 6.7%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.6407 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.6407 - val_loss: 4.3079 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 4.3079\n",
      "Training for 29 horses (7 races, val 1 races): loss per horse: 0.126, val loss per horse: 0.149 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.3630 - categorical_accuracy: 0.0526 - categorical_crossentropy: 3.3630 - val_loss: 3.2028 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.2028\n",
      "Training for 30 horses (19 races, val 3 races): loss per horse: 0.112, val loss per horse: 0.107 Train Accuracy: 5.3%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.4032 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4032 - val_loss: 3.5338 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.5338\n",
      "Training for 31 horses (3 races, val 2 races): loss per horse: 0.110, val loss per horse: 0.114 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "\n",
      "No val data for 32\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9144 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9144\n",
      "Training for 32 horses (2 races, val 0 races): loss per horse: 0.122, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.3908 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3908 - val_loss: 3.7712 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.7712\n",
      "Training for 33 horses (5 races, val 4 races): loss per horse: 0.103, val loss per horse: 0.114 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 34\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.7872 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.7872 - val_loss: 2.5606 - val_categorical_accuracy: 1.0000 - val_categorical_crossentropy: 2.5606\n",
      "Training for 35 horses (1 races, val 1 races): loss per horse: 0.108, val loss per horse: 0.073 Train Accuracy: 0.0%, Val Accuracy: 100.0%\n",
      "\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 3.2298 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2298 - val_loss: 3.2700 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.2700\n",
      "Training for 36 horses (3 races, val 1 races): loss per horse: 0.090, val loss per horse: 0.091 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 37\n",
      "No training or validation data for 38\n",
      "No training or validation data for 39\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 3.9157 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9157 - val_loss: 3.0053 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.0053\n",
      "Training for 40 horses (10 races, val 1 races): loss per horse: 0.098, val loss per horse: 0.075 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 41\n",
      "No training or validation data for 42\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2635 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2635\n",
      "Evaluation only for 43 horses: loss per horse None, val loss per horse: 0.076\n",
      "\n",
      "\n",
      "No val data for 44\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2315 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 4.2315\n",
      "Training for 44 horses (1 races, val 0 races): loss per horse: 0.096, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "No val data for 2\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5325 - categorical_accuracy: 1.0000 - categorical_crossentropy: 0.5325\n",
      "Training for 2 horses (2 races, val 0 races): loss per horse: 0.266, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.0244 - categorical_accuracy: 0.5556 - categorical_crossentropy: 1.0244 - val_loss: 0.9959 - val_categorical_accuracy: 0.2500 - val_categorical_crossentropy: 0.9959\n",
      "Training for 3 horses (27 races, val 4 races): loss per horse: 0.341, val loss per horse: 0.332 Train Accuracy: 55.6%, Val Accuracy: 25.0%\n",
      "\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2003 - categorical_accuracy: 0.4783 - categorical_crossentropy: 1.2003 - val_loss: 1.3618 - val_categorical_accuracy: 0.3111 - val_categorical_crossentropy: 1.3618\n",
      "Training for 4 horses (322 races, val 45 races): loss per horse: 0.300, val loss per horse: 0.340 Train Accuracy: 47.8%, Val Accuracy: 31.1%\n",
      "\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4382 - categorical_accuracy: 0.3803 - categorical_crossentropy: 1.4382 - val_loss: 1.4304 - val_categorical_accuracy: 0.4055 - val_categorical_crossentropy: 1.4304\n",
      "Training for 5 horses (1725 races, val 328 races): loss per horse: 0.288, val loss per horse: 0.286 Train Accuracy: 38.0%, Val Accuracy: 40.5%\n",
      "\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.6048 - categorical_accuracy: 0.3363 - categorical_crossentropy: 1.6048 - val_loss: 1.6392 - val_categorical_accuracy: 0.3100 - val_categorical_crossentropy: 1.6392\n",
      "Training for 6 horses (3916 races, val 900 races): loss per horse: 0.267, val loss per horse: 0.273 Train Accuracy: 33.6%, Val Accuracy: 31.0%\n",
      "\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 1.7604 - categorical_accuracy: 0.3004 - categorical_crossentropy: 1.7604 - val_loss: 1.7382 - val_categorical_accuracy: 0.3258 - val_categorical_crossentropy: 1.7382\n",
      "Training for 7 horses (6469 races, val 1642 races): loss per horse: 0.251, val loss per horse: 0.248 Train Accuracy: 30.0%, Val Accuracy: 32.6%\n",
      "\n",
      "292/292 [==============================] - 0s 1ms/step - loss: 1.8687 - categorical_accuracy: 0.2830 - categorical_crossentropy: 1.8687 - val_loss: 1.8597 - val_categorical_accuracy: 0.2837 - val_categorical_crossentropy: 1.8597\n",
      "Training for 8 horses (9336 races, val 2443 races): loss per horse: 0.234, val loss per horse: 0.232 Train Accuracy: 28.3%, Val Accuracy: 28.4%\n",
      "\n",
      "336/336 [==============================] - 0s 1ms/step - loss: 1.9796 - categorical_accuracy: 0.2568 - categorical_crossentropy: 1.9796 - val_loss: 1.9747 - val_categorical_accuracy: 0.2611 - val_categorical_crossentropy: 1.9747\n",
      "Training for 9 horses (10747 races, val 2643 races): loss per horse: 0.220, val loss per horse: 0.219 Train Accuracy: 25.7%, Val Accuracy: 26.1%\n",
      "\n",
      "426/426 [==============================] - 0s 1ms/step - loss: 2.0798 - categorical_accuracy: 0.2412 - categorical_crossentropy: 2.0798 - val_loss: 2.0812 - val_categorical_accuracy: 0.2401 - val_categorical_crossentropy: 2.0812\n",
      "Training for 10 horses (13625 races, val 3182 races): loss per horse: 0.208, val loss per horse: 0.208 Train Accuracy: 24.1%, Val Accuracy: 24.0%\n",
      "\n",
      "403/403 [==============================] - 0s 1ms/step - loss: 2.1547 - categorical_accuracy: 0.2371 - categorical_crossentropy: 2.1547 - val_loss: 2.1619 - val_categorical_accuracy: 0.2259 - val_categorical_crossentropy: 2.1619\n",
      "Training for 11 horses (12874 races, val 2864 races): loss per horse: 0.196, val loss per horse: 0.197 Train Accuracy: 23.7%, Val Accuracy: 22.6%\n",
      "\n",
      "706/706 [==============================] - 1s 923us/step - loss: 2.2515 - categorical_accuracy: 0.2212 - categorical_crossentropy: 2.2515 - val_loss: 2.2499 - val_categorical_accuracy: 0.2173 - val_categorical_crossentropy: 2.2499\n",
      "Training for 12 horses (22586 races, val 3797 races): loss per horse: 0.188, val loss per horse: 0.187 Train Accuracy: 22.1%, Val Accuracy: 21.7%\n",
      "\n",
      "435/435 [==============================] - 0s 1ms/step - loss: 2.2955 - categorical_accuracy: 0.2212 - categorical_crossentropy: 2.2955 - val_loss: 2.2902 - val_categorical_accuracy: 0.2191 - val_categorical_crossentropy: 2.2902\n",
      "Training for 13 horses (13895 races, val 2729 races): loss per horse: 0.177, val loss per horse: 0.176 Train Accuracy: 22.1%, Val Accuracy: 21.9%\n",
      "\n",
      "652/652 [==============================] - 1s 977us/step - loss: 2.3713 - categorical_accuracy: 0.2055 - categorical_crossentropy: 2.3713 - val_loss: 2.3427 - val_categorical_accuracy: 0.2219 - val_categorical_crossentropy: 2.3427\n",
      "Training for 14 horses (20846 races, val 3718 races): loss per horse: 0.169, val loss per horse: 0.167 Train Accuracy: 20.6%, Val Accuracy: 22.2%\n",
      "\n",
      "401/401 [==============================] - 0s 1ms/step - loss: 2.4187 - categorical_accuracy: 0.2066 - categorical_crossentropy: 2.4187 - val_loss: 2.4338 - val_categorical_accuracy: 0.2035 - val_categorical_crossentropy: 2.4338\n",
      "Training for 15 horses (12821 races, val 2113 races): loss per horse: 0.161, val loss per horse: 0.162 Train Accuracy: 20.7%, Val Accuracy: 20.4%\n",
      "\n",
      "811/811 [==============================] - 1s 1ms/step - loss: 2.4814 - categorical_accuracy: 0.1969 - categorical_crossentropy: 2.4814 - val_loss: 2.4820 - val_categorical_accuracy: 0.1971 - val_categorical_crossentropy: 2.4820\n",
      "Training for 16 horses (25947 races, val 4586 races): loss per horse: 0.155, val loss per horse: 0.155 Train Accuracy: 19.7%, Val Accuracy: 19.7%\n",
      "\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 2.5636 - categorical_accuracy: 0.1720 - categorical_crossentropy: 2.5636 - val_loss: 2.5385 - val_categorical_accuracy: 0.1902 - val_categorical_crossentropy: 2.5385\n",
      "Training for 17 horses (4075 races, val 652 races): loss per horse: 0.151, val loss per horse: 0.149 Train Accuracy: 17.2%, Val Accuracy: 19.0%\n",
      "\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 2.5720 - categorical_accuracy: 0.1825 - categorical_crossentropy: 2.5720 - val_loss: 2.5533 - val_categorical_accuracy: 0.1735 - val_categorical_crossentropy: 2.5533\n",
      "Training for 18 horses (10272 races, val 1643 races): loss per horse: 0.143, val loss per horse: 0.142 Train Accuracy: 18.3%, Val Accuracy: 17.3%\n",
      "\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.7667 - categorical_accuracy: 0.1492 - categorical_crossentropy: 2.7667 - val_loss: 2.6157 - val_categorical_accuracy: 0.3023 - val_categorical_crossentropy: 2.6157\n",
      "Training for 19 horses (657 races, val 43 races): loss per horse: 0.146, val loss per horse: 0.138 Train Accuracy: 14.9%, Val Accuracy: 30.2%\n",
      "\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.7993 - categorical_accuracy: 0.1337 - categorical_crossentropy: 2.7993 - val_loss: 2.9551 - val_categorical_accuracy: 0.0879 - val_categorical_crossentropy: 2.9551\n",
      "Training for 20 horses (1989 races, val 91 races): loss per horse: 0.140, val loss per horse: 0.148 Train Accuracy: 13.4%, Val Accuracy: 8.8%\n",
      "\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 2.8943 - categorical_accuracy: 0.2093 - categorical_crossentropy: 2.8943 - val_loss: 3.1617 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1617\n",
      "Training for 21 horses (43 races, val 3 races): loss per horse: 0.138, val loss per horse: 0.151 Train Accuracy: 20.9%, Val Accuracy: 0.0%\n",
      "\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 2.9766 - categorical_accuracy: 0.1212 - categorical_crossentropy: 2.9766 - val_loss: 2.8355 - val_categorical_accuracy: 0.1538 - val_categorical_crossentropy: 2.8355\n",
      "Training for 22 horses (33 races, val 13 races): loss per horse: 0.135, val loss per horse: 0.129 Train Accuracy: 12.1%, Val Accuracy: 15.4%\n",
      "\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.8590 - categorical_accuracy: 0.0870 - categorical_crossentropy: 2.8590 - val_loss: 3.4074 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.4074\n",
      "Training for 23 horses (23 races, val 5 races): loss per horse: 0.124, val loss per horse: 0.148 Train Accuracy: 8.7%, Val Accuracy: 0.0%\n",
      "\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.1990 - categorical_accuracy: 0.0704 - categorical_crossentropy: 3.1990 - val_loss: 3.1549 - val_categorical_accuracy: 0.1538 - val_categorical_crossentropy: 3.1549\n",
      "Training for 24 horses (71 races, val 13 races): loss per horse: 0.133, val loss per horse: 0.131 Train Accuracy: 7.0%, Val Accuracy: 15.4%\n",
      "\n",
      "\n",
      "No val data for 25\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3834 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3834\n",
      "Training for 25 horses (5 races, val 0 races): loss per horse: 0.135, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.2275 - categorical_accuracy: 0.1667 - categorical_crossentropy: 3.2275 - val_loss: 2.9434 - val_categorical_accuracy: 0.1429 - val_categorical_crossentropy: 2.9434\n",
      "Training for 26 horses (6 races, val 7 races): loss per horse: 0.124, val loss per horse: 0.113 Train Accuracy: 16.7%, Val Accuracy: 14.3%\n",
      "\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 3.0444 - categorical_accuracy: 0.5000 - categorical_crossentropy: 3.0444 - val_loss: 3.6706 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.6706\n",
      "Training for 27 horses (4 races, val 2 races): loss per horse: 0.113, val loss per horse: 0.136 Train Accuracy: 50.0%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 3.2395 - categorical_accuracy: 0.0667 - categorical_crossentropy: 3.2395 - val_loss: 3.3885 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3885\n",
      "Training for 28 horses (30 races, val 10 races): loss per horse: 0.116, val loss per horse: 0.121 Train Accuracy: 6.7%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.6392 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.6392 - val_loss: 4.2872 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 4.2872\n",
      "Training for 29 horses (7 races, val 1 races): loss per horse: 0.125, val loss per horse: 0.148 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.3582 - categorical_accuracy: 0.0526 - categorical_crossentropy: 3.3582 - val_loss: 3.1900 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.1900\n",
      "Training for 30 horses (19 races, val 3 races): loss per horse: 0.112, val loss per horse: 0.106 Train Accuracy: 5.3%, Val Accuracy: 0.0%\n",
      "\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.3688 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3688 - val_loss: 3.5248 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.5248\n",
      "Training for 31 horses (3 races, val 2 races): loss per horse: 0.109, val loss per horse: 0.114 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "\n",
      "No val data for 32\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8790 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.8790\n",
      "Training for 32 horses (2 races, val 0 races): loss per horse: 0.121, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 3.4043 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.4043 - val_loss: 3.7783 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.7783\n",
      "Training for 33 horses (5 races, val 4 races): loss per horse: 0.103, val loss per horse: 0.114 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 34\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 3.7585 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.7585 - val_loss: 2.5302 - val_categorical_accuracy: 1.0000 - val_categorical_crossentropy: 2.5302\n",
      "Training for 35 horses (1 races, val 1 races): loss per horse: 0.107, val loss per horse: 0.072 Train Accuracy: 0.0%, Val Accuracy: 100.0%\n",
      "\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.2016 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.2016 - val_loss: 3.3217 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.3217\n",
      "Training for 36 horses (3 races, val 1 races): loss per horse: 0.089, val loss per horse: 0.092 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 37\n",
      "No training or validation data for 38\n",
      "No training or validation data for 39\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 3.9136 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.9136 - val_loss: 3.0535 - val_categorical_accuracy: 0.0000e+00 - val_categorical_crossentropy: 3.0535\n",
      "Training for 40 horses (10 races, val 1 races): loss per horse: 0.098, val loss per horse: 0.076 Train Accuracy: 0.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training or validation data for 41\n",
      "No training or validation data for 42\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3149 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 3.3149\n",
      "Evaluation only for 43 horses: loss per horse None, val loss per horse: 0.077\n",
      "\n",
      "\n",
      "No val data for 44\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2638 - categorical_accuracy: 0.0000e+00 - categorical_crossentropy: 4.2638\n",
      "Training for 44 horses (1 races, val 0 races): loss per horse: 0.097, val loss per horse: nan Train Accuracy: 0.0%, Val Accuracy: nan%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "CPU times: user 37min 6s, sys: 39.9 s, total: 37min 46s\n",
      "Wall time: 37min 24s\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "%%time\n",
    "sequential_sgd_regression = LogisticRegressionModel(source=SOURCE, n_features=N_FEATURES)\n",
    "sequential_sgd_regression, training_history =sequential_training.train_on_each_horse_with_epochs(source=SOURCE, winning_model=sequential_sgd_regression, n_epochs=5, verbose=True)\n",
    "\n",
    "sequential_sgd_regression.save_model(prefix=\"48_col_5_epochs_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 59 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf13118c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 60 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcef92b1830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 61 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf39758c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 62 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf0ae50200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf3b3998c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf1f3f15f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf3b399200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcee9dab320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcefb2794d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcef9909170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf1ec714d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf1e6c2f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf098f19e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf39748f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "(0.2264257987458943, 0.0924753657808301, 0.32284263959390863)\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "exact_top_1 = errors.compute_validation_error(source=SOURCE, k=1,winning_model=sequential_sgd_regression, validation_method=errors.exact_top_k)\n",
    "print(errors.compute_overall_average(exact_top_1))\n",
    "\n",
    "kappa_cohen_1 = errors.compute_validation_error(source=SOURCE, \n",
    "                                                            k=1,\n",
    "                                                            winning_model=sequential_sgd_regression, \n",
    "                                                            validation_method=errors.kappa_cohen_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.15088790848989717, 0.003320176199196662, 0.2571769690533504)\n"
     ]
    }
   ],
   "source": [
    "print(errors.compute_overall_average(kappa_cohen_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing on same races w/ 3 horses with odds 3 races (4 races in total)\n",
      "Mean Predicted probas of actual race result: 49.138% (Random: 19.251%, Odds: 40.856%)\n",
      "\n",
      "Comparing on same races w/ 4 horses with odds 40 races (45 races in total)\n",
      "Mean Predicted probas of actual race result: 29.930% (Random: 21.939%, Odds: 37.649%)\n",
      "\n",
      "Comparing on same races w/ 5 horses with odds 287 races (328 races in total)\n",
      "Mean Predicted probas of actual race result: 27.692% (Random: 19.517%, Odds: 34.718%)\n",
      "\n",
      "Comparing on same races w/ 6 horses with odds 737 races (900 races in total)\n",
      "Mean Predicted probas of actual race result: 21.423% (Random: 16.428%, Odds: 27.936%)\n",
      "\n",
      "Comparing on same races w/ 7 horses with odds 1285 races (1642 races in total)\n",
      "Mean Predicted probas of actual race result: 20.109% (Random: 14.496%, Odds: 26.404%)\n",
      "\n",
      "Comparing on same races w/ 8 horses with odds 1764 races (2443 races in total)\n",
      "Mean Predicted probas of actual race result: 17.859% (Random: 12.687%, Odds: 24.742%)\n",
      "\n",
      "Comparing on same races w/ 9 horses with odds 1850 races (2643 races in total)\n",
      "Mean Predicted probas of actual race result: 15.764% (Random: 11.345%, Odds: 22.285%)\n",
      "\n",
      "Comparing on same races w/ 10 horses with odds 2196 races (3182 races in total)\n",
      "Mean Predicted probas of actual race result: 14.303% (Random: 9.983%, Odds: 20.823%)\n",
      "\n",
      "Comparing on same races w/ 11 horses with odds 1946 races (2864 races in total)\n",
      "Mean Predicted probas of actual race result: 13.265% (Random: 9.042%, Odds: 19.537%)\n",
      "\n",
      "Comparing on same races w/ 12 horses with odds 2581 races (3797 races in total)\n",
      "Mean Predicted probas of actual race result: 11.914% (Random: 8.450%, Odds: 17.866%)\n",
      "\n",
      "Comparing on same races w/ 13 horses with odds 1645 races (2729 races in total)\n",
      "Mean Predicted probas of actual race result: 11.732% (Random: 7.636%, Odds: 17.128%)\n",
      "\n",
      "Comparing on same races w/ 14 horses with odds 2193 races (3718 races in total)\n",
      "Mean Predicted probas of actual race result: 11.183% (Random: 7.045%, Odds: 15.760%)\n",
      "\n",
      "Comparing on same races w/ 15 horses with odds 1132 races (2113 races in total)\n",
      "Mean Predicted probas of actual race result: 10.187% (Random: 6.696%, Odds: 15.303%)\n",
      "\n",
      "Comparing on same races w/ 16 horses with odds 2413 races (4586 races in total)\n",
      "Mean Predicted probas of actual race result: 9.507% (Random: 6.211%, Odds: 14.458%)\n",
      "\n",
      "Comparing on same races w/ 17 horses with odds 286 races (652 races in total)\n",
      "Mean Predicted probas of actual race result: 9.014% (Random: 6.060%, Odds: 13.064%)\n",
      "\n",
      "Comparing on same races w/ 18 horses with odds 698 races (1643 races in total)\n",
      "Mean Predicted probas of actual race result: 8.553% (Random: 5.615%, Odds: 13.413%)\n",
      "\n",
      "Comparing on same races w/ 19 horses with odds 14 races (43 races in total)\n",
      "Mean Predicted probas of actual race result: 7.838% (Random: 5.584%, Odds: 12.937%)\n",
      "\n",
      "Comparing on same races w/ 20 horses with odds 26 races (91 races in total)\n",
      "Mean Predicted probas of actual race result: 5.554% (Random: 5.728%, Odds: 9.525%)\n",
      "\n",
      "Comparing on same races w/ 21 horses with odds 0 races (3 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 22 horses with odds 2 races (13 races in total)\n",
      "Mean Predicted probas of actual race result: 5.490% (Random: 5.431%, Odds: 3.539%)\n",
      "\n",
      "Comparing on same races w/ 23 horses with odds 1 races (5 races in total)\n",
      "Mean Predicted probas of actual race result: 4.366% (Random: 3.565%, Odds: 14.491%)\n",
      "\n",
      "Comparing on same races w/ 24 horses with odds 5 races (13 races in total)\n",
      "Mean Predicted probas of actual race result: 4.592% (Random: 5.514%, Odds: 9.607%)\n",
      "\n",
      "Comparing on same races w/ 26 horses with odds 0 races (7 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 27 horses with odds 0 races (2 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 28 horses with odds 1 races (10 races in total)\n",
      "Mean Predicted probas of actual race result: 3.361% (Random: 5.774%, Odds: 3.105%)\n",
      "\n",
      "Comparing on same races w/ 29 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 30 horses with odds 0 races (3 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 31 horses with odds 1 races (2 races in total)\n",
      "Mean Predicted probas of actual race result: 1.986% (Random: 3.741%, Odds: 2.156%)\n",
      "\n",
      "Comparing on same races w/ 33 horses with odds 0 races (4 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 35 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 36 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 40 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "Comparing on same races w/ 43 horses with odds 0 races (1 races in total)\n",
      "Mean Predicted probas of actual race result: nan% (Random: nan%, Odds: nan%)\n",
      "\n",
      "On 3 races with 3 horses,R² of winning model: 0.33, R² of odds: 0.16, [R² of random model: -1.16 (should be closed to 0)]\n",
      "On 40 races with 4 horses,R² of winning model: 0.03, R² of odds: 0.17, [R² of random model: -0.26 (should be closed to 0)]\n",
      "On 287 races with 5 horses,R² of winning model: 0.12, R² of odds: 0.25, [R² of random model: -0.20 (should be closed to 0)]\n",
      "On 737 races with 6 horses,R² of winning model: 0.07, R² of odds: 0.16, [R² of random model: -0.16 (should be closed to 0)]\n",
      "On 1285 races with 7 horses,R² of winning model: 0.10, R² of odds: 0.19, [R² of random model: -0.14 (should be closed to 0)]\n",
      "On 1764 races with 8 horses,R² of winning model: 0.10, R² of odds: 0.21, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 1850 races with 9 horses,R² of winning model: 0.09, R² of odds: 0.19, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 2196 races with 10 horses,R² of winning model: 0.09, R² of odds: 0.19, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 1946 races with 11 horses,R² of winning model: 0.09, R² of odds: 0.19, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 2581 races with 12 horses,R² of winning model: 0.08, R² of odds: 0.18, [R² of random model: -0.11 (should be closed to 0)]\n",
      "On 1645 races with 13 horses,R² of winning model: 0.10, R² of odds: 0.18, [R² of random model: -0.12 (should be closed to 0)]\n",
      "On 2193 races with 14 horses,R² of winning model: 0.11, R² of odds: 0.17, [R² of random model: -0.13 (should be closed to 0)]\n",
      "On 1132 races with 15 horses,R² of winning model: 0.09, R² of odds: 0.18, [R² of random model: -0.10 (should be closed to 0)]\n",
      "On 2413 races with 16 horses,R² of winning model: 0.09, R² of odds: 0.18, [R² of random model: -0.11 (should be closed to 0)]\n",
      "On 286 races with 17 horses,R² of winning model: 0.09, R² of odds: 0.16, [R² of random model: -0.09 (should be closed to 0)]\n",
      "On 698 races with 18 horses,R² of winning model: 0.09, R² of odds: 0.19, [R² of random model: -0.10 (should be closed to 0)]\n",
      "On 14 races with 19 horses,R² of winning model: 0.06, R² of odds: 0.11, [R² of random model: -0.12 (should be closed to 0)]\n",
      "On 26 races with 20 horses,R² of winning model: -0.02, R² of odds: 0.08, [R² of random model: -0.05 (should be closed to 0)]\n",
      "On 0 races with 21 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 2 races with 22 horses,R² of winning model: 0.02, R² of odds: -0.08, [R² of random model: 0.06 (should be closed to 0)]\n",
      "On 1 races with 23 horses,R² of winning model: 0.00, R² of odds: 0.38, [R² of random model: -0.06 (should be closed to 0)]\n",
      "On 5 races with 24 horses,R² of winning model: -0.02, R² of odds: 0.25, [R² of random model: 0.08 (should be closed to 0)]\n",
      "On 0 races with 26 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 27 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 1 races with 28 horses,R² of winning model: -0.02, R² of odds: -0.04, [R² of random model: 0.14 (should be closed to 0)]\n",
      "On 0 races with 29 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 30 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 1 races with 31 horses,R² of winning model: -0.14, R² of odds: -0.12, [R² of random model: 0.04 (should be closed to 0)]\n",
      "On 0 races with 33 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 35 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 36 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 40 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "On 0 races with 43 horses,R² of winning model: nan, R² of odds: nan, [R² of random model: nan (should be closed to 0)]\n",
      "Average Winning Model R²: nan, Average Odds R²: nan (Average Random R²: nan)\n",
      "Combined Winning Model R²: 0.091, Combined Odds R²: 0.185 (Combined Random R²: -0.121) \n",
      "Delta Model vs Odds: -0.093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_horses_r_squared': {3: {'model_r_squared': 0.33145758754856647,\n",
       "   'odds_r_squared': 0.16174488735854864,\n",
       "   'random_r_squared': -1.1567870085819605,\n",
       "   'n_races': 3,\n",
       "   'n_rejected_races': 0},\n",
       "  4: {'model_r_squared': 0.033495435272820284,\n",
       "   'odds_r_squared': 0.17443008029053897,\n",
       "   'random_r_squared': -0.2638522211438925,\n",
       "   'n_races': 40,\n",
       "   'n_rejected_races': 0},\n",
       "  5: {'model_r_squared': 0.11510322718679211,\n",
       "   'odds_r_squared': 0.24501564971518353,\n",
       "   'random_r_squared': -0.19893567369267884,\n",
       "   'n_races': 287,\n",
       "   'n_rejected_races': 0},\n",
       "  6: {'model_r_squared': 0.07255207162942268,\n",
       "   'odds_r_squared': 0.1640584706648457,\n",
       "   'random_r_squared': -0.15517132130257028,\n",
       "   'n_races': 737,\n",
       "   'n_rejected_races': 0},\n",
       "  7: {'model_r_squared': 0.09951489200238761,\n",
       "   'odds_r_squared': 0.1870765948715638,\n",
       "   'random_r_squared': -0.13839741292274388,\n",
       "   'n_races': 1285,\n",
       "   'n_rejected_races': 0},\n",
       "  8: {'model_r_squared': 0.10015771698589016,\n",
       "   'odds_r_squared': 0.2072795225420433,\n",
       "   'random_r_squared': -0.13273779087946846,\n",
       "   'n_races': 1764,\n",
       "   'n_rejected_races': 0},\n",
       "  9: {'model_r_squared': 0.08983334326181014,\n",
       "   'odds_r_squared': 0.18956543110915947,\n",
       "   'random_r_squared': -0.12703857708015232,\n",
       "   'n_races': 1850,\n",
       "   'n_rejected_races': 0},\n",
       "  10: {'model_r_squared': 0.08722892616342293,\n",
       "   'odds_r_squared': 0.19096965205005967,\n",
       "   'random_r_squared': -0.12783852545077123,\n",
       "   'n_races': 2196,\n",
       "   'n_rejected_races': 0},\n",
       "  11: {'model_r_squared': 0.08941979422880864,\n",
       "   'odds_r_squared': 0.1896927642180799,\n",
       "   'random_r_squared': -0.12764658592494604,\n",
       "   'n_races': 1946,\n",
       "   'n_rejected_races': 0},\n",
       "  12: {'model_r_squared': 0.07920319750094895,\n",
       "   'odds_r_squared': 0.1833125991975766,\n",
       "   'random_r_squared': -0.10589854352339101,\n",
       "   'n_races': 2581,\n",
       "   'n_rejected_races': 0},\n",
       "  13: {'model_r_squared': 0.09744501284963258,\n",
       "   'odds_r_squared': 0.1841538668018441,\n",
       "   'random_r_squared': -0.1165002294251356,\n",
       "   'n_races': 1645,\n",
       "   'n_rejected_races': 0},\n",
       "  14: {'model_r_squared': 0.10531798485762,\n",
       "   'odds_r_squared': 0.1737785016245904,\n",
       "   'random_r_squared': -0.1300366266980204,\n",
       "   'n_races': 2193,\n",
       "   'n_rejected_races': 0},\n",
       "  15: {'model_r_squared': 0.09111709797347722,\n",
       "   'odds_r_squared': 0.17677641403009992,\n",
       "   'random_r_squared': -0.10486404109202874,\n",
       "   'n_races': 1132,\n",
       "   'n_rejected_races': 0},\n",
       "  16: {'model_r_squared': 0.08946647248226092,\n",
       "   'odds_r_squared': 0.17542939588385553,\n",
       "   'random_r_squared': -0.10507382516597152,\n",
       "   'n_races': 2413,\n",
       "   'n_rejected_races': 0},\n",
       "  17: {'model_r_squared': 0.0910155414394278,\n",
       "   'odds_r_squared': 0.16135182313906538,\n",
       "   'random_r_squared': -0.0943542132137809,\n",
       "   'n_races': 286,\n",
       "   'n_rejected_races': 0},\n",
       "  18: {'model_r_squared': 0.09165998241046469,\n",
       "   'odds_r_squared': 0.19420519647851187,\n",
       "   'random_r_squared': -0.10483472458192211,\n",
       "   'n_races': 698,\n",
       "   'n_rejected_races': 0},\n",
       "  19: {'model_r_squared': 0.06223648639536816,\n",
       "   'odds_r_squared': 0.11230459802929926,\n",
       "   'random_r_squared': -0.11826500737581225,\n",
       "   'n_races': 14,\n",
       "   'n_rejected_races': 0},\n",
       "  20: {'model_r_squared': -0.021556186942714994,\n",
       "   'odds_r_squared': 0.08270865809153527,\n",
       "   'random_r_squared': -0.05308841779760454,\n",
       "   'n_races': 26,\n",
       "   'n_rejected_races': 0},\n",
       "  21: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  22: {'model_r_squared': 0.023940251761805142,\n",
       "   'odds_r_squared': -0.08146388191884335,\n",
       "   'random_r_squared': 0.0558460086150101,\n",
       "   'n_races': 2,\n",
       "   'n_rejected_races': 0},\n",
       "  23: {'model_r_squared': 0.0013170371926940483,\n",
       "   'odds_r_squared': 0.38395360522813304,\n",
       "   'random_r_squared': -0.06330193028890996,\n",
       "   'n_races': 1,\n",
       "   'n_rejected_races': 0},\n",
       "  24: {'model_r_squared': -0.02256013370783072,\n",
       "   'odds_r_squared': 0.25132385608732,\n",
       "   'random_r_squared': 0.07791873016621809,\n",
       "   'n_races': 5,\n",
       "   'n_rejected_races': 0},\n",
       "  26: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  27: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  28: {'model_r_squared': -0.018231550353038584,\n",
       "   'odds_r_squared': -0.042018247996860714,\n",
       "   'random_r_squared': 0.1441852152110834,\n",
       "   'n_races': 1,\n",
       "   'n_rejected_races': 0},\n",
       "  29: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  30: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  31: {'model_r_squared': -0.14127673891443582,\n",
       "   'odds_r_squared': -0.11735959147483821,\n",
       "   'random_r_squared': 0.043136282751492505,\n",
       "   'n_races': 1,\n",
       "   'n_rejected_races': 0},\n",
       "  33: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  35: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  36: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  40: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0},\n",
       "  43: {'model_r_squared': nan,\n",
       "   'odds_r_squared': nan,\n",
       "   'random_r_squared': nan,\n",
       "   'n_races': 0,\n",
       "   'n_rejected_races': 0}},\n",
       " 'average_model_r_squared': nan,\n",
       " 'average_odds_r_squared': nan,\n",
       " 'average_random_r_squared': nan,\n",
       " 'combined_model_r_squared': 0.09139847065875051,\n",
       " 'combined_odds_r_squared': 0.18451068776442836,\n",
       " 'combined_random_r_squared': -0.12068816769876145,\n",
       " 'delta_model_odds': -0.09311221710567785}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared.compute_mcfadden_r_squared(source=SOURCE,winning_model=sequential_sgd_regression, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "pretrained_sequential_sgd_regression = LogisticRegressionModel(source=SOURCE,n_features=N_FEATURES)\n",
    "pretrained_sequential_sgd_regression, training_history =sequential_training.pretrain_on_each_subraces(source=SOURCE,\n",
    "                                                                                                      winning_model=pretrained_sequential_sgd_regression, \n",
    "                                                                                                      n_permutations=10, \n",
    "                                                                                                      verbose=True)\n",
    "\n",
    "\n",
    "exact_top_1 = errors.compute_validation_error(source=SOURCE, k=1,winning_model=pretrained_sequential_sgd_regression, validation_method=errors.exact_top_k)\n",
    "print(errors.compute_overall_average(exact_top_1))\n",
    "\n",
    "kappa_cohen_1 = errors.compute_validation_error(source=SOURCE, \n",
    "                                                            k=1,\n",
    "                                                            winning_model=pretrained_sequential_sgd_regression, \n",
    "                                                            validation_method=errors.kappa_cohen_like)\n",
    "print(errors.compute_overall_average(kappa_cohen_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "pretrained_sequential_sgd_regression, training_history =sequential_training.train_on_each_horse_with_epochs(source=SOURCE, winning_model=pretrained_sequential_sgd_regression, n_epochs=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "exact_top_1 = errors.compute_validation_error(source=SOURCE, k=1,winning_model=pretrained_sequential_sgd_regression, validation_method=errors.exact_top_k)\n",
    "print(errors.compute_overall_average(exact_top_1))\n",
    "\n",
    "kappa_cohen_1 = errors.compute_validation_error(source=SOURCE, \n",
    "                                                            k=1,\n",
    "                                                            winning_model=pretrained_sequential_sgd_regression, \n",
    "                                                            validation_method=errors.kappa_cohen_like)\n",
    "print(errors.compute_overall_average(kappa_cohen_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_sequential_sgd_regression.save_model(prefix=\"pretrained_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training and validation data for 2\n",
      "[07:16:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 3 horses (27 races): loss per horse: 0.019, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "[07:16:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 4 horses (322 races): loss per horse: 0.003, val loss per horse: 0.472 Train Accuracy: 100.0%, Val Accuracy: 28.9%\n",
      "\n",
      "[07:16:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 5 horses (1725 races): loss per horse: 0.003, val loss per horse: 0.358 Train Accuracy: 100.0%, Val Accuracy: 33.2%\n",
      "\n",
      "[07:17:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 6 horses (3916 races): loss per horse: 0.007, val loss per horse: 0.330 Train Accuracy: 100.0%, Val Accuracy: 26.4%\n",
      "\n",
      "[07:17:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 7 horses (6469 races): loss per horse: 0.015, val loss per horse: 0.283 Train Accuracy: 100.0%, Val Accuracy: 26.9%\n",
      "\n",
      "[07:18:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 8 horses (9336 races): loss per horse: 0.022, val loss per horse: 0.259 Train Accuracy: 99.9%, Val Accuracy: 25.3%\n",
      "\n",
      "[07:20:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 9 horses (10747 races): loss per horse: 0.020, val loss per horse: 0.246 Train Accuracy: 100.0%, Val Accuracy: 21.6%\n",
      "\n",
      "[07:23:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 10 horses (13625 races): loss per horse: 0.025, val loss per horse: 0.234 Train Accuracy: 100.0%, Val Accuracy: 18.6%\n",
      "\n",
      "[07:27:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 11 horses (12874 races): loss per horse: 0.016, val loss per horse: 0.221 Train Accuracy: 100.0%, Val Accuracy: 17.8%\n",
      "\n",
      "[07:32:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 12 horses (22586 races): loss per horse: 0.036, val loss per horse: 0.205 Train Accuracy: 99.7%, Val Accuracy: 17.1%\n",
      "\n",
      "[07:40:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 13 horses (13895 races): loss per horse: 0.011, val loss per horse: 0.200 Train Accuracy: 100.0%, Val Accuracy: 15.8%\n",
      "\n",
      "[07:46:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 14 horses (20846 races): loss per horse: 0.020, val loss per horse: 0.186 Train Accuracy: 100.0%, Val Accuracy: 15.6%\n",
      "\n",
      "[07:57:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 15 horses (12821 races): loss per horse: 0.007, val loss per horse: 0.185 Train Accuracy: 100.0%, Val Accuracy: 14.0%\n",
      "\n",
      "[08:05:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 16 horses (25947 races): loss per horse: 0.020, val loss per horse: 0.172 Train Accuracy: 100.0%, Val Accuracy: 14.1%\n",
      "\n",
      "[08:21:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 17 horses (4075 races): loss per horse: 0.001, val loss per horse: 0.182 Train Accuracy: 100.0%, Val Accuracy: 12.0%\n",
      "\n",
      "[08:24:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 18 horses (10272 races): loss per horse: 0.002, val loss per horse: 0.167 Train Accuracy: 100.0%, Val Accuracy: 13.1%\n",
      "\n",
      "[08:33:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 19 horses (657 races): loss per horse: 0.001, val loss per horse: 0.186 Train Accuracy: 100.0%, Val Accuracy: 7.0%\n",
      "\n",
      "[08:33:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 20 horses (1989 races): loss per horse: 0.001, val loss per horse: 0.187 Train Accuracy: 100.0%, Val Accuracy: 0.0%\n",
      "\n",
      "[08:34:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 21 horses (43 races): loss per horse: 0.016, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "[08:35:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 22 horses (33 races): loss per horse: 0.021, val loss per horse: 0.476 Train Accuracy: 100.0%, Val Accuracy: 0.0%\n",
      "\n",
      "[08:36:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 23 horses (23 races): loss per horse: 0.027, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "[08:36:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 24 horses (71 races): loss per horse: 0.008, val loss per horse: 0.159 Train Accuracy: 100.0%, Val Accuracy: 0.0%\n",
      "\n",
      "No training and validation data for 25\n",
      "Not enough training examples for 26 horses (only 6 races)\n",
      "Not enough training examples for 27 horses (only 4 races)\n",
      "[08:36:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 28 horses (30 races): loss per horse: 0.020, val loss per horse: 0.342 Train Accuracy: 100.0%, Val Accuracy: 0.0%\n",
      "\n",
      "Not enough training examples for 29 horses (only 7 races)\n",
      "[08:37:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 30 horses (19 races): loss per horse: 0.031, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "Not enough training examples for 31 horses (only 3 races)\n",
      "No training and validation data for 32\n",
      "Not enough training examples for 33 horses (only 5 races)\n",
      "No training and validation data for 34\n",
      "Not enough training examples for 35 horses (only 1 races)\n",
      "Not enough training examples for 36 horses (only 3 races)\n",
      "No training and validation data for 37\n",
      "No training and validation data for 38\n",
      "No training and validation data for 39\n",
      "[08:37:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training for 40 horses (10 races): loss per horse: 0.027, val loss per horse: nan Train Accuracy: 100.0%, Val Accuracy: nan%\n",
      "\n",
      "No training and validation data for 41\n",
      "No training and validation data for 42\n",
      "Not enough training examples for 43 horses (only 0 races)\n",
      "No training and validation data for 44\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_model() got an unexpected keyword argument 'prefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5cc48b0d8229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgboost_winning_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattened_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_per_n_horses_races\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSOURCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinning_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXGBoostWinningModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSOURCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgboost_winning_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"48_col_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: save_model() got an unexpected keyword argument 'prefix'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9h 15min 31s, sys: 1min 23s, total: 9h 16min 54s\n",
      "Wall time: 1h 20min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "\n",
    "xgboost_winning_model, training_history = flattened_training.train_per_n_horses_races(source=SOURCE, winning_model=XGBoostWinningModel(source=SOURCE), verbose=True)\n",
    "xgboost_winning_model.save_model(prefix=\"48_col_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "26\n",
      "Could not save model for 26 horses: need to call fit or load_model beforehand\n",
      "27\n",
      "Could not save model for 27 horses: need to call fit or load_model beforehand\n",
      "28\n",
      "29\n",
      "Could not save model for 29 horses: need to call fit or load_model beforehand\n",
      "30\n",
      "31\n",
      "Could not save model for 31 horses: need to call fit or load_model beforehand\n",
      "33\n",
      "Could not save model for 33 horses: need to call fit or load_model beforehand\n",
      "35\n",
      "Could not save model for 35 horses: need to call fit or load_model beforehand\n",
      "36\n",
      "Could not save model for 36 horses: need to call fit or load_model beforehand\n",
      "40\n",
      "43\n",
      "Could not save model for 43 horses: need to call fit or load_model beforehand\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.core import XGBoostError\n",
    "\n",
    "from constants import SAVED_MODELS_DIR, Sources\n",
    "from winning_horse_models import AbstractWinningModel, FlattenMixin\n",
    "from winning_horse_models import ModelNotCreatedOnceError\n",
    "from sklearn.exceptions import NotFittedError\n",
    "self=xgboost_winning_model\n",
    "prefix=\"48_col_\"\n",
    "if self.__class__.__name__ not in os.listdir(SAVED_MODELS_DIR):\n",
    "    os.mkdir(os.path.join(SAVED_MODELS_DIR, self.__class__.__name__))\n",
    "for n_horse, n_horse_model in self.n_horses_models.items():\n",
    "    print(n_horse)\n",
    "    try:\n",
    "        n_horse_model.save_model(\n",
    "            fname=os.path.join(\n",
    "                SAVED_MODELS_DIR,\n",
    "                self.__class__.__name__,\n",
    "                f\"{prefix}{self.__class__.__name__}_{n_horse}.pickle\",\n",
    "            )\n",
    "        )\n",
    "    except XGBoostError as e:\n",
    "        print(f\"Could not save model for {n_horse} horses: {e}\")\n",
    "    except NotFittedError as e:\n",
    "        print(f\"Could not save model for {n_horse} horses: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_horses=22\n",
    "source=SOURCE\n",
    "from training_procedures.flattened_training import _one_hot_encode, _extend_y_pred_with_unseen_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_model=XGBoostWinningModel(source=SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/.pyenv/versions/3.7.9/envs/benter-project_venv/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:14:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "x, y, _ = import_data.get_races_per_horse_number(\n",
    "    source=source,\n",
    "    n_horses=n_horses,\n",
    "    on_split=\"train\",\n",
    "    x_format=\"flattened\",\n",
    "    y_format=\"index_first\",\n",
    ")\n",
    "x_val, y_val, _ = import_data.get_races_per_horse_number(\n",
    "    source=source,\n",
    "    n_horses=n_horses,\n",
    "    on_split=\"val\",\n",
    "    x_format=\"flattened\",\n",
    "    y_format=\"index_first\",\n",
    ")\n",
    "\n",
    "model = winning_model.get_n_horses_model(n_horses=n_horses)\n",
    "\n",
    "model = model.fit(X=x, y=y)\n",
    "        \n",
    "y_pred = model.predict_proba(x)\n",
    "y_true = _one_hot_encode(y, n_horses=n_horses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = _extend_y_pred_with_unseen_classes(\n",
    "                    missing_indexes=[\n",
    "                        i for i in range(n_horses) if i not in model.classes_\n",
    "                    ],\n",
    "                    y_pred=y_pred,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021177981473086062"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.log_loss(y_true=y_true, y_pred=y_pred) / n_horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.place(np.zeros((43, n_horses)),np.arange((43, n_horses) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '21' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f0e516b99425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_horses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret '21' as a data type"
     ]
    }
   ],
   "source": [
    "np.put(np.zeros(43, n_horses),np.array([model.classes_]*43), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_indexes ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_y_pred = y_pred\n",
    "for missing_index in sorted(i for i in range(n_horses) if i not in model.classes_):\n",
    "    extended_y_pred= np.concatenate([extended_y_pred[:,:missing_index],np.zeros(len(x)).reshape((len(x),1)), extended_y_pred[:,missing_index:]] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 19)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 19)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 21)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_winning_model.n_features =48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for axis 0 with size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4a6ebb64f4ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexact_top_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_validation_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSOURCE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwinning_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgboost_winning_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_top_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_overall_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexact_top_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m kappa_cohen_1 = errors.compute_validation_error(source=SOURCE, \n\u001b[1;32m      5\u001b[0m                                                             \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Prose/Mathieu/Benter-Project/winning_validation/errors.py\u001b[0m in \u001b[0;36mcompute_validation_error\u001b[0;34m(source, k, validation_method, winning_model, selected_features_index, extra_features_func, verbose)\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mrank_race\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     np.apply_along_axis(\n\u001b[0;32m--> 110\u001b[0;31m                         \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrankdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                     ),\n\u001b[1;32m    112\u001b[0m                 )\n",
      "\u001b[0;32m~/Prose/Mathieu/Benter-Project/winning_validation/errors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    105\u001b[0m             [\n\u001b[1;32m    106\u001b[0m                 \u001b[0mvalidation_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_race\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 for rank_r, rank_h in zip(\n\u001b[0m\u001b[1;32m    108\u001b[0m                     \u001b[0mrank_race\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     np.apply_along_axis(\n",
      "\u001b[0;32m~/Prose/Mathieu/Benter-Project/winning_validation/errors.py\u001b[0m in \u001b[0;36mexact_top_k\u001b[0;34m(rank_race, rank_hat, k)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexact_top_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_race\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     return np.all(\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mrank_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_true_ordered_topk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank_race\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;34m==\u001b[0m \u001b[0mrank_race\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_true_ordered_topk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank_race\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     )\n",
      "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for axis 0 with size 15"
     ]
    }
   ],
   "source": [
    "exact_top_1 = errors.compute_validation_error(source=SOURCE, k=1,winning_model=xgboost_winning_model, validation_method=errors.exact_top_k)\n",
    "print(errors.compute_overall_average(exact_top_1))\n",
    "\n",
    "kappa_cohen_1 = errors.compute_validation_error(source=SOURCE, \n",
    "                                                            k=1,\n",
    "                                                            winning_model=xgboost_winning_model, \n",
    "                                                            validation_method=errors.kappa_cohen_like)\n",
    "print(errors.compute_overall_average(kappa_cohen_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared.compute_mcfadden_r_squared(source=SOURCE,winning_model=xgboost_winning_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for SklearnModel in [\n",
    "     #sklearn.DecisionTreeModel, sklearn.SVCModel, #sklearn.KNNModel,\n",
    "                     #sklearn.RandomForestModel, \n",
    "    #sklearn.AdaBoostModel,\n",
    "                     # sklearn.GradientBoostingModel, sklearn.GaussianNBModel, sklearn.LDAModel,\n",
    "                     sklearn.SGDModel\n",
    "                    ]:\n",
    "    print(SklearnModel.__name__)\n",
    "    sklearn_winning_model, training_history = flattened_training.train_per_n_horses_races(source=SOURCE, winning_model=SklearnModel(), verbose=True)\n",
    "    sklearn_winning_model.save_model()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sklearn_winning_model, training_history = flattened_training.train_per_n_horses_races(source=SOURCE, winning_model=sklearn.LogisticRegressionModel(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_winning_model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, on_split=SOURCE, \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_horses=10\n",
    "y_format = \"first_position\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_df = import_data.get_split_date(source=source, on_split=on_split)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "race_dfs = []\n",
    "for _, race_df in rh_df[rh_df[\"n_horses\"] == n_horses].groupby(\"race_id\"):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data.extract_x_y(\n",
    "            race_df=race_df,\n",
    "            x_format=\"sequential_per_horse\",\n",
    "            y_format=y_format,\n",
    "            source=source,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_race = (race_df[\"horse_place\"] == 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_race.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_race = preprocess.preprocess(race_horse_df=race_df, source=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(x_race).all().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"horse_place\"].isna().all() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_race = (race_df[\"horse_place\"] == 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_df['race_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_df['horse_place'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_datetime64tz_dtype(rh_df.dtypes[\"race_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_df.dtypes[\"horse_id\"] == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.datetime64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_df.dtypes[\"race_datetime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_datetime64tz_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.import_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horse_place']=df['horse_place'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horse_place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(os.path.join(DATA_DIR, \"unibet_data_with_features.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horse_place']=df['horse_place'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horse_place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(os.path.join(DATA_DIR, \"unibet_data_with_features.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
