{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mathieu/Prose/Mathieu/Benter-Project\n"
     ]
    }
   ],
   "source": [
    "#%cd C:/Users/Mathieu/Desktop/Projets/Benter\n",
    "%cd /home/mathieu/Prose/Mathieu/Benter-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/.pyenv/versions/3.7.9/envs/benter-project_venv/lib/python3.7/site-packages/tqdm/std.py:699: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from itertools import combinations\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "from scipy.stats import rankdata\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "from utils import import_data\n",
    "from winning_validation import errors\n",
    "from winning_validation import r_squared\n",
    "from winning_horse_models import sklearn\n",
    "from winning_horse_models.dl_shared_layers import LogisticRegressionModel, DLSharedLayersModel, DLLayersGeneratorModel\n",
    "from winning_horse_models.xgboost import XGBoostWinningModel\n",
    "from winning_horse_models.catboost import CatboostWinningModel\n",
    "from winning_horse_models.lgbm import LGBMWinningModel\n",
    "from training_procedures import sequential_training, flattened_training\n",
    "from constants import Sources, SplitSets, XFormats, YFormats\n",
    "from catboost import CatBoostClassifier\n",
    "from utils import preprocess\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from database.setup import create_sqlalchemy_session\n",
    "from models.race import Race\n",
    "from models.runner import Runner\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "tqdm.pandas()\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = Sources.UNIBET\n",
    "N_FEATURES = preprocess.get_n_preprocessed_feature_columns(source=SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLSharedLGBMWinningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture --no-stdout\n",
    "space = {'layers':[{'type':'Dense', 'n_units':1}]}\n",
    "\n",
    "model =DLLayersGeneratorModel(source=SOURCE, n_features = N_FEATURES, hyperparameters=space, name='1')\n",
    "    \n",
    "model, _ = sequential_training.train_on_n_horses(source=SOURCE, winning_model=model, n_horses=10, n_epochs=0, start_training_at=dt.datetime.now(),\n",
    "                                                 n_epochs_per_n_horses=1, verbose=True)\n",
    "\n",
    "res=r_squared.compute_mcfadden_r_squared_on_n_horses(source=SOURCE,winning_model=model, n_horses=10, verbose=True)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _ = import_data.get_races_per_horse_number(\n",
    "    source=SOURCE,\n",
    "    n_horses=10,\n",
    "    on_split=SplitSets.TRAIN,\n",
    "    x_format=XFormats.SEQUENTIAL,\n",
    "    y_format=YFormats.INDEX_FIRST,\n",
    "    preprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13625, 10, 120)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduction_model=FastICA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_x=x.reshape(x.shape[0]*x.shape[1], x.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastICA(n_components=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_reduction_model.fit(horse_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastICA(n_components=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_reduction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLLayersGeneratorModelDminReduction(SequentialMixin, AbstractWinningModel):\n",
    "\n",
    "    _NotFittedModelError = _ShouldNotBeTriggeredException\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        hyperparameters: Optional[dict] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self._layers_per_n_horses: Dict[int, Any] = {}\n",
    "        self._dim\n",
    "        self._hyperparameters = hyperparameters\n",
    "\n",
    "    def get_layers(self, hyperparameters: Optional[dict] = None):\n",
    "        if hyperparameters is None:\n",
    "            return tf.keras.layers.Dense(1)\n",
    "        if len(hyperparameters[\"layers\"]) == 1:\n",
    "            layer = hyperparameters[\"layers\"][0]\n",
    "            assert layer[\"type\"] == \"Dense\"\n",
    "            return tf.keras.layers.Dense(layer[\"n_units\"])\n",
    "\n",
    "        assert hyperparameters[\"layers\"][-1][\"n_units\"] == 1\n",
    "        layers = []\n",
    "        for layer in hyperparameters[\"layers\"]:\n",
    "            assert layer[\"type\"] in (\"Dense\", \"Dropout\")\n",
    "            if layer[\"type\"] == \"Dense\":\n",
    "                params = {\"units\": layer[\"n_units\"]}\n",
    "                if \"kernel_regularizer\" in layer:\n",
    "                    assert layer[\"kernel_regularizer\"][\"type\"] == \"l2\"\n",
    "                    params[\"kernel_regularizer\"] = tf.keras.regularizers.l2(\n",
    "                        l2=layer[\"kernel_regularizer\"][\"l2\"]\n",
    "                    )\n",
    "                layers.append(tf.keras.layers.Dense(**params))\n",
    "                continue\n",
    "            layers.append(tf.keras.layers.Dropout(layer[\"rate\"]))\n",
    "        return tf.keras.Sequential(layers=layers)\n",
    "\n",
    "    def _create_n_horses_model(self, n_horses: int):\n",
    "        self._layers_per_n_horses[n_horses] = self.get_layers(self._hyperparameters)\n",
    "        inputs = tf.keras.Input(shape=(n_horses, self.n_features))\n",
    "        unstacked = tf.keras.layers.Lambda(lambda x: tf.unstack(x, axis=1))(inputs)\n",
    "        dense_outputs = [\n",
    "            self._layers_per_n_horses[n_horses](x) for x in unstacked\n",
    "        ]  # our generated layer\n",
    "        merged = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(dense_outputs)\n",
    "        outputs = tf.keras.layers.Reshape(target_shape=(n_horses,))(merged)\n",
    "        outputs = tf.keras.layers.Lambda(\n",
    "            lambda x: tf.keras.activations.softmax(x, axis=-1)\n",
    "        )(outputs)\n",
    "\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            optimizer=\"rmsprop\",\n",
    "            metrics=[\"categorical_accuracy\", \"categorical_crossentropy\"],\n",
    "        )\n",
    "        model.build(input_shape=(None, n_horses, self.n_features))\n",
    "        return model\n",
    "\n",
    "    def save_model(self, prefix: Optional[str] = None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, name: str, prefix: Optional[str] = None):\n",
    "        raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
