{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mathieu/Mindsay/mathieu/Benter-Project\n"
     ]
    }
   ],
   "source": [
    "#%cd C:/Users/Mathieu/Desktop/Projets/Benter\n",
    "%cd /home/mathieu/Mindsay/mathieu/Benter-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train \n",
    "\n",
    "- predict the best horse in a given race\n",
    "\n",
    "\n",
    "### TODO\n",
    "- try to predict a given distribution according to ranks, instead of the first one\n",
    "- try to predict best among all combinaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from itertools import combinations\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "from scipy.stats import rankdata\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "from utils import import_data\n",
    "from utils import winning_validation\n",
    "from winning_horse_models import sklearn\n",
    "from winning_horse_models.logistic_regression import LogisticRegressionModel\n",
    "from winning_horse_models.xgboost import XGBoostWinningModel\n",
    "from winning_horse_models.lgbm import LGBMWinningModel\n",
    "\n",
    "SOURCE = \"PMU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequential_sgd_regression = LogisticRegressionModel.load_model(trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/Mindsay/mathieu/Benter-Project/utils/import_data.py:168: DtypeWarning: Columns (35,46,47,61,62,63,64,87) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  rh_df = get_split_date(source=source, on_split=on_split)\n"
     ]
    }
   ],
   "source": [
    "exact_top_1 = winning_validation.compute_validation_error(source=SOURCE, \n",
    "                                                          k=1,\n",
    "                                                          winning_model=sequential_sgd_regression, \n",
    "                                                          validation_method=winning_validation.exact_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_cohen_1 = winning_validation.compute_validation_error(source=SOURCE, \n",
    "                                                            k=1,\n",
    "                                                            winning_model=sequential_sgd_regression, \n",
    "                                                            validation_method=winning_validation.kappa_cohen_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_3 = winning_validation.compute_validation_error(source=SOURCE, \n",
    "                                                             k=3,\n",
    "                                                             winning_model=sequential_sgd_regression, \n",
    "                                                             validation_method=winning_validation.precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23681652490886998, 0.09218307006885379, 0.27112191170514377)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_validation.compute_overall_average(exact_top_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15875357464821155, -0.0014250643409744832, 0.19765694181213814)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_validation.compute_overall_average(kappa_cohen_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43272982569835416, 0.2813263666680168, 0.45352181133298225)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_validation.compute_overall_average(precision_at_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgboost_winning_model = XGBoostWinningModel.load_model(trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/.pyenv/versions/3.7.4/envs/venv_benter/lib/python3.7/site-packages/joblib-0.15.1-py3.7.egg/joblib/memory.py:531: DtypeWarning: Columns (35,46,47,61,62,63,64,87) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  out, metadata = self.call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For races w/ 3 horses, 9 races in val, top 1 in right order: 55.556% (Random: 22.222%, Odds 55.556%)\n",
      "For races w/ 4 horses, 77 races in val, top 1 in right order: 31.169% (Random: 35.065%, Odds 50.649%)\n",
      "For races w/ 5 horses, 354 races in val, top 1 in right order: 33.616% (Random: 16.949%, Odds 44.350%)\n",
      "For races w/ 6 horses, 829 races in val, top 1 in right order: 23.643% (Random: 16.888%, Odds 36.188%)\n",
      "For races w/ 7 horses, 1489 races in val, top 1 in right order: 24.312% (Random: 14.909%, Odds 37.139%)\n",
      "For races w/ 8 horses, 1914 races in val, top 1 in right order: 24.922% (Random: 11.755%, Odds 35.005%)\n",
      "For races w/ 9 horses, 2072 races in val, top 1 in right order: 22.683% (Random: 12.403%, Odds 33.687%)\n",
      "For races w/ 10 horses, 2457 races in val, top 1 in right order: 18.030% (Random: 10.623%, Odds 30.322%)\n",
      "For races w/ 11 horses, 2269 races in val, top 1 in right order: 18.070% (Random: 9.079%, Odds 28.735%)\n",
      "For races w/ 12 horses, 2740 races in val, top 1 in right order: 17.956% (Random: 8.102%, Odds 26.606%)\n",
      "For races w/ 13 horses, 2204 races in val, top 1 in right order: 18.058% (Random: 8.167%, Odds 21.279%)\n",
      "For races w/ 14 horses, 2446 races in val, top 1 in right order: 16.517% (Random: 7.236%, Odds 20.237%)\n",
      "For races w/ 15 horses, 1978 races in val, top 1 in right order: 16.532% (Random: 6.623%, Odds 20.526%)\n",
      "For races w/ 16 horses, 2379 races in val, top 1 in right order: 15.090% (Random: 6.515%, Odds 21.101%)\n",
      "For races w/ 17 horses, 614 races in val, top 1 in right order: 12.704% (Random: 6.840%, Odds 16.124%)\n",
      "For races w/ 18 horses, 757 races in val, top 1 in right order: 12.417% (Random: 5.020%, Odds 21.268%)\n",
      "For races w/ 19 horses, 44 races in val, top 1 in right order: 13.636% (Random: 6.818%, Odds 11.364%)\n",
      "For races w/ 20 horses, 33 races in val, top 1 in right order: 6.061% (Random: 0.000%, Odds 12.121%)\n"
     ]
    }
   ],
   "source": [
    "exact_top_1 = winning_validation.compute_validation_error(source=SOURCE, k=1,winning_model=xgboost_winning_model, validation_method=winning_validation.exact_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgmb_winning_model = LGBMWinningModel.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For races w/ 3 horses, 9 races in val, top 1 in right order: 44.444% (Random: 22.222%, Odds 55.556%)\n",
      "For races w/ 4 horses, 77 races in val, top 1 in right order: 29.870% (Random: 35.065%, Odds 50.649%)\n",
      "For races w/ 5 horses, 354 races in val, top 1 in right order: 31.356% (Random: 16.949%, Odds 44.350%)\n",
      "For races w/ 6 horses, 829 races in val, top 1 in right order: 25.814% (Random: 16.888%, Odds 36.188%)\n",
      "For races w/ 7 horses, 1489 races in val, top 1 in right order: 26.998% (Random: 14.909%, Odds 37.139%)\n",
      "For races w/ 8 horses, 1914 races in val, top 1 in right order: 27.691% (Random: 11.755%, Odds 35.005%)\n",
      "For races w/ 9 horses, 2072 races in val, top 1 in right order: 22.442% (Random: 12.403%, Odds 33.687%)\n",
      "For races w/ 10 horses, 2457 races in val, top 1 in right order: 20.228% (Random: 10.623%, Odds 30.322%)\n",
      "For races w/ 11 horses, 2269 races in val, top 1 in right order: 19.392% (Random: 9.079%, Odds 28.735%)\n",
      "For races w/ 12 horses, 2740 races in val, top 1 in right order: 20.073% (Random: 8.102%, Odds 26.606%)\n",
      "For races w/ 13 horses, 2204 races in val, top 1 in right order: 18.058% (Random: 8.167%, Odds 21.279%)\n",
      "For races w/ 14 horses, 2446 races in val, top 1 in right order: 19.787% (Random: 7.236%, Odds 20.237%)\n",
      "For races w/ 15 horses, 1978 races in val, top 1 in right order: 17.644% (Random: 6.623%, Odds 20.526%)\n",
      "For races w/ 16 horses, 2379 races in val, top 1 in right order: 15.805% (Random: 6.515%, Odds 21.101%)\n",
      "For races w/ 17 horses, 614 races in val, top 1 in right order: 11.889% (Random: 6.840%, Odds 16.124%)\n",
      "For races w/ 18 horses, 757 races in val, top 1 in right order: 14.795% (Random: 5.020%, Odds 21.268%)\n",
      "For races w/ 19 horses, 44 races in val, top 1 in right order: 11.364% (Random: 6.818%, Odds 11.364%)\n",
      "For races w/ 20 horses, 33 races in val, top 1 in right order: 6.061% (Random: 0.000%, Odds 12.121%)\n"
     ]
    }
   ],
   "source": [
    "exact_top_1 = winning_validation.compute_validation_error(source=SOURCE, k=1,winning_model=lgmb_winning_model, validation_method=winning_validation.exact_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel\n",
      "(0.030470628793524007, 0.002130053016071174, 0.19769219098749824)\n",
      "SVCModel\n",
      "(0.04685053088385765, 0.002130053016071174, 0.19769219098749824)\n",
      "KNNModel\n",
      "(0.1837746083693874, 0.002130053016071174, 0.19769219098749824)\n",
      "RandomForestModel\n",
      "(0.09921375068151626, 0.002130053016071174, 0.19769219098749824)\n",
      "AdaBoostModel\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1ba9ee12b30a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     ]:\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSklearnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msklearn_winning_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSklearnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     kappa_cohen_1 = winning_validation.compute_validation_error(source=SOURCE, k=1,winning_model=sklearn_winning_model, \n\u001b[1;32m     10\u001b[0m                                                               validation_method=winning_validation.kappa_cohen_like)\n",
      "\u001b[0;32m~/Mindsay/mathieu/Benter-Project/winning_horse_models/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVED_MODELS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVED_MODELS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for SklearnModel in [\n",
    "     sklearn.DecisionTreeModel, sklearn.SVCModel, sklearn.KNNModel,\n",
    "                     sklearn.RandomForestModel, sklearn.AdaBoostModel,\n",
    "                     sklearn.GradientBoostingModel, sklearn.GaussianNBModel, sklearn.LDAModel,\n",
    "                     sklearn.QDAModel, sklearn.SGDModel\n",
    "                    ]:\n",
    "    print(SklearnModel.__name__)\n",
    "    sklearn_winning_model = SklearnModel.load_model()\n",
    "    kappa_cohen_1 = winning_validation.compute_validation_error(source=SOURCE, k=1,winning_model=sklearn_winning_model, \n",
    "                                                              validation_method=winning_validation.kappa_cohen_like)\n",
    "    print(winning_validation.compute_overall_average(kappa_cohen_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
